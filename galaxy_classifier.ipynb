{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Galaxy Classifiers (Spiral, Elliptical, Odd objects)\n",
        "\n",
        "## 1. Base on Zernike moments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOYeHQ5feUyM"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import (roc_curve, roc_auc_score, auc, log_loss,\n",
        "                             precision_score, recall_score, f1_score,\n",
        "                             accuracy_score, classification_report,\n",
        "                             ConfusionMatrixDisplay, confusion_matrix)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from tensorflow.keras.layers import (Dense, Activation, Dropout,BatchNormalization, Input, Conv1D, Conv2D, Flatten,\n",
        "                             Convolution2D, MaxPool2D, MaxPooling1D, MaxPooling2D)\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "\n",
        "#Scikit_learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (roc_curve, roc_auc_score, auc, log_loss,\n",
        "                             precision_score, recall_score, f1_score,\n",
        "                             accuracy_score, classification_report,\n",
        "                             ConfusionMatrixDisplay, confusion_matrix)\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import label_binarize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQYGb6x82ngb",
        "outputId": "1fac4203-e2aa-4c1f-e4e1-3287c39c8529"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# If using Google Colab.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute the ZMs:\n",
        "\n",
        "##### The ZEMO python package [https://pypi.org/project/ZEMO/] [https://github.com/hmddev1/ZEMO] can be used to compute Zernike moments (Zms) for your images. This library is described in a research paper you can find online [[arxiv:2308.13562](https://arxiv.org/abs/2308.13562v2)]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ZEMO import zemo\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "image_size = 200\n",
        "zernike_order = 45\n",
        "\n",
        "ZBFSTR = zemo.zernike_bf(image_size, zernike_order, 1)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- To use our image data use these directories from the repo.:\n",
        "        \n",
        "        - Spiral: \n",
        "        - Elliptical:\n",
        "        - Odd objects: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = r'/path/to/your/directory/galaxy' \n",
        "\n",
        "image_files = [os.path.join(path, filename) for filename in os.listdir(path) if filename.endswith('.jpg')]\n",
        "len(image_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ZZ = []\n",
        "\n",
        "for img_path in image_files:\n",
        "    image = cv2.imread(img_path)\n",
        "    resized_image = cv2.resize(image, (image_size, image_size))\n",
        "    im = resized_image[:,:,0]\n",
        "    Z = np.abs(zemo.zernike_mom(np.array(im), ZBFSTR))\n",
        "    ZZ.append(Z)\n",
        "\n",
        "\n",
        "# Save the ZMs as data frame\n",
        "df = pd.DataFrame(ZZ)\n",
        "df.to_csv('/path/to/your/directory/spiral_zms.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- To use our Zernike moment features data set, use these directories from the repo.:\n",
        "        \n",
        "        - Spiral: \n",
        "        - Elliptical:\n",
        "        - Odd objects:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7HrfV4O2p5o"
      },
      "outputs": [],
      "source": [
        "spiral_data = pd.read_csv('/path/to/your/directory/spiral_zms.csv')\n",
        "elliptical_data = pd.read_csv('/path/to/your/directory/elliptical_zms.csv')\n",
        "odd_data = pd.read_csv('/path/to/your/directory/odd_zms.csv')\n",
        "\n",
        "spiral_data.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
        "elliptical_data.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
        "odd_data.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
        "\n",
        "all_zm_data = np.concatenate([spiral_data, elliptical_data, odd_data])\n",
        "np.shape(all_zm_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fDMPYw78c46",
        "outputId": "51ceaafe-3161-49c8-89c2-27b46403b04e"
      },
      "outputs": [],
      "source": [
        "# Labels\n",
        "\n",
        "num_class = 3\n",
        "spiral_label = [0] * len(spiral_data)\n",
        "elliptical_label = [1] * len(elliptical_data)\n",
        "odd_label = [2] * len(odd_data)\n",
        "all_labels = np.concatenate([spiral_label, elliptical_label, odd_label])\n",
        "len(all_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Check the class weights:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AZt2NmHoYaR",
        "outputId": "20bccf57-c967-49a0-8a63-0022824ca4b2"
      },
      "outputs": [],
      "source": [
        "total_samples = len(all_zm_data)\n",
        "class_weights = {\n",
        "    0: total_samples / (3*len(spiral_data)),  # Class 0 (or Class 1) weight\n",
        "    1: total_samples / (3*len(elliptical_data)),   # Class 1 (or Class 2) weight\n",
        "    2: total_samples / (3*len(odd_data))    # Class 2 (or Class 3) weight\n",
        "}\n",
        "\n",
        "print(\"Class Weights based on Inverse Class Frequency:\")\n",
        "print(\"Class 1 Weight:\", class_weights[0])\n",
        "print(\"Class 2 Weight:\", class_weights[1])\n",
        "print(\"Class 3 Weight:\", class_weights[2])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fit the SVM model for 10 iterations and calculate the standard deviation.\n",
        "##### (You can save the performance materials and the models outputs.) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfFrEO3Nh_ag"
      },
      "outputs": [],
      "source": [
        "y_test_list = []\n",
        "models = []\n",
        "Y_pred = []\n",
        "accs = []\n",
        "cons = []\n",
        "aucs = []\n",
        "fprs = []\n",
        "tprs = []\n",
        "test_indx=[]\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(all_zm_data, all_labels, np.arange(len(all_labels)), test_size=0.25, shuffle=True, random_state=None)\n",
        "    y_test_list.append(y_test)\n",
        "    test_indx.append(test_indices)\n",
        "\n",
        "    class_weights = {0: len(all_zm_data) / (3*len(spiral_data)), 1: len(all_zm_data) / (3*len(elliptical_data)), 2: len(all_zm_data) / (3*len(odd_data))}\n",
        "\n",
        "    model = SVC(kernel='rbf', probability=True, C=1.5, gamma='scale',class_weight=class_weights)\n",
        "    gz2_training_model = model.fit(X_train, y_train)\n",
        "    models.append(gz2_training_model)\n",
        "\n",
        "    y_score = gz2_training_model.predict_proba(X_test)  # Use predicted probabilities for ROC vurve\n",
        "    y_test_bin = label_binarize(y_test, classes=list(range(3)))  # Binarize the true labels\n",
        "\n",
        "    y_pred = gz2_training_model.predict(X_test)\n",
        "    Y_pred.append(y_pred)\n",
        "\n",
        "    con0 = metrics.confusion_matrix(y_test, y_pred)\n",
        "    cons.append(con0)\n",
        "\n",
        "    acc = metrics.accuracy_score(y_test, y_pred)\n",
        "    accs.append(acc)\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "\n",
        "    for i in range(3):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    fprs.append(fpr)\n",
        "    tprs.append(tpr)\n",
        "    aucs.append(roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QptS0Y9Mma-d",
        "outputId": "445fa4a3-ba4c-4477-f252-8bbc2417c90c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9050443081117928 0.003266298173336322\n",
            "Mean of all AUC values: 0.9770435503194648\n",
            "Standard Deviation of all AUC values: 0.020048188703497838\n"
          ]
        }
      ],
      "source": [
        "print(np.mean(accs), np.std(accs))\n",
        "\n",
        "# Calculate mean of all AUC values\n",
        "all_auc_values = [auc_value for auc_dict in aucs for auc_value in auc_dict.values()]\n",
        "mean_auc = np.mean(all_auc_values)\n",
        "std_auc = np.std(all_auc_values)\n",
        "\n",
        "print(\"Mean of all AUC values:\", mean_auc)\n",
        "print(\"Standard Deviation of all AUC values:\", std_auc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKTBySNFgbx4"
      },
      "outputs": [],
      "source": [
        "output_path = '/path/to/your/directory'\n",
        "import os\n",
        "pickle_filename = 'tprs_svm_zms_galaxy_classifier.pickle'\n",
        "pickle_filepath = os.path.join(output_path, pickle_filename)\n",
        "\n",
        "with open(pickle_filepath, 'wb') as pickle_file:\n",
        "    pickle.dump(tprs, pickle_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fit the 1D-CNN model for 10 iterations and calculate the standard deviation.\n",
        "##### (You can save the performance materials and the models outputs.) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from math import e\n",
        "\n",
        "y_test_list = []\n",
        "models = []\n",
        "Y_pred = []\n",
        "accs = []\n",
        "cons = []\n",
        "aucs = []\n",
        "fprs = []\n",
        "tprs = []\n",
        "test_indx=[]\n",
        "\n",
        "b_size = 64\n",
        "e_num = 30\n",
        "\n",
        "for i in range (10):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(all_zm_data, all_labels, test_size=0.25, shuffle=True, random_state=None)\n",
        "    y_test_list.append(y_test)\n",
        "    test_indx.append(test_indices)\n",
        "\n",
        "    class_weights = {0: len(all_zm_data) / (3*len(spiral_data)), 1: len(all_zm_data) / (3*len(elliptical_data)), 2: len(all_zm_data) / (3*len(odd_data))}\n",
        "    y_train_encoded = to_categorical(y_train, num_classes=3)\n",
        "\n",
        "    # input\n",
        "    x = Input(shape=(all_zm_data.shape[1],1))\n",
        "\n",
        "    #hidden layers\n",
        "    c0 = Conv1D(256, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    b0 = BatchNormalization()(c0)\n",
        "    m0 = MaxPooling1D(pool_size=2)(b0)\n",
        "    d0 = Dropout(0.1)(m0)\n",
        "\n",
        "    c1 = Conv1D(128, kernel_size=3, strides=2, padding=\"same\")(d0)\n",
        "    b1 = BatchNormalization()(c1)\n",
        "    m1 = MaxPooling1D(pool_size=2)(b1)\n",
        "    d1 = Dropout(0.1)(m1)\n",
        "\n",
        "    c2 = Conv1D(64, kernel_size=3, strides=2, padding=\"same\")(d1)\n",
        "    b2 = BatchNormalization()(c2)\n",
        "    m2 = MaxPooling1D(pool_size=2)(b2)\n",
        "    d2 = Dropout(0.1)(m2)\n",
        "\n",
        "    f = Flatten()(d2)\n",
        "\n",
        "    de0 = Dense(64, activation='relu')(f)\n",
        "    de1 = Dense(32, activation='relu')(de0)\n",
        "    de2 = Dense(3, activation='softmax')(de1)\n",
        "\n",
        "    model = Model(inputs=x, outputs=de2, name=\"cnn_zm_45_galaxy_classifier\")\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    # Callback Functions\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "    history = model.fit(\n",
        "    X_train, y_train_encoded,\n",
        "    batch_size=b_size,\n",
        "    epochs=e_num,\n",
        "    class_weight=class_weights,\n",
        "    verbose = 1,\n",
        "    callbacks=es,\n",
        "    validation_split=0.1\n",
        "    )\n",
        "    models.append(history)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "    Y_pred.append(y_pred_labels)\n",
        "\n",
        "    y_test_bin = label_binarize(y_test, classes=list(range(3)))  # Binarize the true labels\n",
        "\n",
        "    con0 = metrics.confusion_matrix(y_test, y_pred_labels)\n",
        "    cons.append(con0)\n",
        "\n",
        "    acc = metrics.accuracy_score(y_test, y_pred_labels)\n",
        "    accs.append(acc)\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "\n",
        "    for i in range(3):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    fprs.append(fpr)\n",
        "    tprs.append(tpr)\n",
        "    aucs.append(roc_auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Base on original images \n",
        "- (Vision Transformers used as data augmentation tools on the Galaxy and Non-Galaxy images.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import packages \n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import (Dense, Dropout, Input,Conv2D, Flatten,\n",
        "                             MaxPooling2D,BatchNormalization)\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import ResNet50, VGG16\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "#Torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The load_galaxy_images functions uses for read and pre-process the input images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_galaxy_images(data_dir, target_size):\n",
        "        \n",
        "        \"\"\"\n",
        "        Loads, resizes, and processes all JPG images from the specified directory.\n",
        "\n",
        "        Parameters:\n",
        "        data_dir (str): The directory containing the JPG images to be processed.\n",
        "        target_size (tuple): The target size for resizing the images, specified as (width, height).\n",
        "\n",
        "        Returns:\n",
        "        list: A list of PIL Image objects, each representing a resized and processed image.\n",
        "\n",
        "        The function performs the following steps:\n",
        "        1. Lists all JPG image files in the specified directory.\n",
        "        2. Reads each image using OpenCV.\n",
        "        3. Resizes each image to the specified target size.\n",
        "        4. Scales the pixel values and converts the image to a format compatible with PIL.\n",
        "        5. Converts each resized image to a PIL Image object.\n",
        "        6. Appends each PIL Image object to a list.\n",
        "        7. Returns the list of PIL Image objects.\n",
        "        \"\"\"\n",
        "\n",
        "        all_images = []\n",
        "\n",
        "        file_path = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir) if filename.endswith('.jpg')]\n",
        "\n",
        "        for img in file_path:\n",
        "            image = cv2.imread(img)\n",
        "            resized_images=cv2.resize(image, target_size)\n",
        "            resized_images = (resized_images * 255).astype(np.uint8)\n",
        "            pil_images = Image.fromarray(resized_images)\n",
        "            all_images.append(pil_images)\n",
        "\n",
        "        return all_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- To use our image data use these directories from the repo.:\n",
        "        \n",
        "        - Spiral: \n",
        "        - Elliptical:\n",
        "        - Odd objects: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "el_dir = '/content/drive/MyDrive/Data/GZ2_E_S_I/new/crop/elliptical'\n",
        "sp_dir = '/content/drive/MyDrive/Data/GZ2_E_S_I/new/crop/spiral'\n",
        "odd_dir = '/content/drive/MyDrive/Data/GZ2_E_S_I/new/crop/odd'\n",
        "\n",
        "image_size = 200\n",
        "\n",
        "sp_img = load_galaxy_images(sp_dir, target_size=(image_size,image_size))\n",
        "el_img = load_galaxy_images(el_dir, target_size=(image_size,image_size))\n",
        "odd_img = load_galaxy_images(odd_dir, target_size=(image_size,image_size))\n",
        "\n",
        "all_data = np.concatenate([sp_img, el_img, odd_img])\n",
        "np.shape(all_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### vision transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# transforms for training data\n",
        "train_transform = transforms.Compose([transforms.CenterCrop(image_size),\n",
        "                                      transforms.RandomRotation(90),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.RandomVerticalFlip(),\n",
        "                                      transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0), ratio=(0.99, 1.01)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                                      ])\n",
        "\n",
        "\n",
        "# transforms for test data\n",
        "test_transform = transforms.Compose([transforms.CenterCrop(image_size),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                                      ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_classes = 3\n",
        "\n",
        "label_s = [0] * len(sp_img)\n",
        "label_e = [1] * len(el_img)\n",
        "label_o = [2] * len(odd_img)\n",
        "all_labels = np.concatenate([label_s, label_e, label_o])\n",
        "len(all_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "b_size =64\n",
        "e_num = 30\n",
        "\n",
        "X_list=[]\n",
        "y_list=[]\n",
        "models=[]\n",
        "Y_pred=[]\n",
        "accs=[]\n",
        "cons=[]\n",
        "aucs=[]\n",
        "fprs=[]\n",
        "tprs=[]\n",
        "\n",
        "for i in range (10):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(all_data, all_labels, test_size=0.25, shuffle=True, random_state=None)\n",
        "    X_list.append(X_train)\n",
        "    y_list.append(y_train)\n",
        "\n",
        "    class_weights = {0: len(all_data) / (3*len(sp_img)), 1: len(all_data) / (3*len(el_img)), 2: len(all_data) / (3*len(ir_img))}\n",
        "    y_train_encoded = to_categorical(y_train, num_classes=3)\n",
        "\n",
        "    # Training data\n",
        "    transformed_X_train=[]\n",
        "    for i in range(len(X_train)):\n",
        "      transformed_train_images = train_transform(X_train[i])\n",
        "      new_image = np.transpose(transformed_train_images, (1, 2, 0))\n",
        "      transformed_X_train.append(new_image)\n",
        "\n",
        "    # Testing data\n",
        "    transformed_X_test=[]\n",
        "    for j in range(len(X_test)):\n",
        "      transformed_test_images = test_transform(X_test[j])\n",
        "      new_images = np.transpose(transformed_test_images, (1, 2, 0))\n",
        "      transformed_X_test.append(new_images)\n",
        "\n",
        "    # input\n",
        "    x = Input(shape=(image_size,image_size,3))\n",
        "\n",
        "    #hidden layers\n",
        "    c0 = Conv2D(256, kernel_size=(3,3), strides=(1,1), padding=\"same\")(x)\n",
        "    b0 = BatchNormalization()(c0)\n",
        "    m0 = MaxPooling2D(pool_size=(2, 2))(b0)\n",
        "    d0 = Dropout(0.1)(m0)\n",
        "\n",
        "    c1 = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding=\"same\")(m0)\n",
        "    b1 = BatchNormalization()(c1)\n",
        "    m1 = MaxPooling2D(pool_size=(2, 2))(b1)\n",
        "    d1 = Dropout(0.1)(m1)\n",
        "\n",
        "    c2 = Conv2D(64, kernel_size=(3,3), strides=(1,1), padding=\"same\")(m1)\n",
        "    b2 = BatchNormalization()(c2)\n",
        "    m2 = MaxPooling2D(pool_size=(2, 2))(b2)\n",
        "    d2 = Dropout(0.1)(m2)\n",
        "\n",
        "    f = Flatten()(m2)\n",
        "\n",
        "    de0 = Dense(64, activation='relu')(f)\n",
        "    de1 = Dense(32, activation='relu')(de0)\n",
        "    de2 = Dense(3, activation='softmax')(de1)\n",
        "\n",
        "    model = Model(inputs=x, outputs=de2, name=\"cnn_transformer_galaxy_nonegalaxy\")\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    # Callback Functions\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "    history = model.fit(\n",
        "    np.array(transformed_X_train), y_train_encoded,\n",
        "    batch_size=b_size,\n",
        "    epochs=e_num,\n",
        "    verbose = 1,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=es,\n",
        "    validation_split=0.1\n",
        "    )\n",
        "    models.append(history)\n",
        "\n",
        "    y_pred = model.predict(np.array(transformed_X_test))\n",
        "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "    Y_pred.append(y_pred_labels)\n",
        "\n",
        "    con0 = metrics.confusion_matrix(y_test, y_pred_labels)\n",
        "    cons.append(con0)\n",
        "\n",
        "    acc = metrics.accuracy_score(y_test, y_pred_labels)\n",
        "    accs.append(acc)\n",
        "\n",
        "    y_test_bin = label_binarize(y_test, classes=list(range(3)))  # Binarize the true labels\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "\n",
        "    for i in range(3):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    fprs.append(fpr)\n",
        "    tprs.append(tpr)\n",
        "    aucs.append(roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "b_size =64\n",
        "e_num = 30\n",
        "\n",
        "X_list=[]\n",
        "y_list=[]\n",
        "models=[]\n",
        "Y_pred=[]\n",
        "accs=[]\n",
        "cons=[]\n",
        "aucs=[]\n",
        "fprs=[]\n",
        "tprs=[]\n",
        "\n",
        "for i in range (10):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(all_data, all_labels, test_size=0.25, shuffle=True, random_state=None)\n",
        "    X_list.append(X_train)\n",
        "    y_list.append(y_train)\n",
        "\n",
        "    class_weights = {0: len(all_data) / (3*len(sp_img)), 1: len(all_data) / (3*len(el_img)), 2: len(all_data) / (3*len(ir_img))}\n",
        "    y_train_encoded = to_categorical(y_train, num_classes=3)\n",
        "\n",
        "    # Training data\n",
        "    transformed_X_train=[]\n",
        "    for i in range(len(X_train)):\n",
        "      transformed_train_images = train_transform(X_train[i])\n",
        "      new_image = np.transpose(transformed_train_images, (1, 2, 0))\n",
        "      transformed_X_train.append(new_image)\n",
        "\n",
        "    # Testing data\n",
        "    transformed_X_test=[]\n",
        "    for j in range(len(X_test)):\n",
        "      transformed_test_images = test_transform(X_test[j])\n",
        "      new_images = np.transpose(transformed_test_images, (1, 2, 0))\n",
        "      transformed_X_test.append(new_images)\n",
        "\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(64, activation='relu')(x)  # Add your custom layers here\n",
        "    output = Dense(3, activation='softmax')(x)  # 3 classes, so 3 output units with softmax activation\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Callback Functions\n",
        "    es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=10)\n",
        "\n",
        "    history = model.fit(\n",
        "    np.array(transformed_X_train), y_train_encoded,\n",
        "    batch_size=b_size,\n",
        "    epochs=e_num,\n",
        "    verbose = 1,\n",
        "    callbacks=es,\n",
        "    class_weight= class_weights,\n",
        "    validation_split=0.1\n",
        "    )\n",
        "    models.append(history)\n",
        "\n",
        "    y_score = model.predict(np.array(transformed_X_test))  # Use predicted probabilities\n",
        "    y_pred_labels = np.argmax(y_score, axis=1)\n",
        "    Y_pred.append(y_pred_labels)\n",
        "\n",
        "    con0 = metrics.confusion_matrix(y_test, y_pred_labels)\n",
        "    cons.append(con0)\n",
        "\n",
        "    acc = metrics.accuracy_score(y_test, y_pred_labels)\n",
        "    accs.append(acc)\n",
        "\n",
        "    y_test_bin = label_binarize(y_test, classes=list(range(3)))  # Binarize the true labels\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "\n",
        "    for i in range(3):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    fprs.append(fpr)\n",
        "    tprs.append(tpr)\n",
        "    aucs.append(roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "b_size =64\n",
        "e_num = 30\n",
        "\n",
        "X_list=[]\n",
        "y_list=[]\n",
        "models=[]\n",
        "Y_pred=[]\n",
        "accs=[]\n",
        "cons=[]\n",
        "aucs=[]\n",
        "fprs=[]\n",
        "tprs=[]\n",
        "\n",
        "for i in range (10):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(all_data, all_labels, test_size=0.25, shuffle=True, random_state=None)\n",
        "    X_list.append(X_train)\n",
        "    y_list.append(y_train)\n",
        "\n",
        "    class_weights = {0: len(all_data) / (3*len(sp_img)), 1: len(all_data) / (3*len(el_img)), 2: len(all_data) / (3*len(ir_img))}\n",
        "    y_train_encoded = to_categorical(y_train, num_classes=3)\n",
        "\n",
        "    # Training data\n",
        "    transformed_X_train=[]\n",
        "    for i in range(len(X_train)):\n",
        "      transformed_train_images = train_transform(X_train[i])\n",
        "      new_image = np.transpose(transformed_train_images, (1, 2, 0))\n",
        "      transformed_X_train.append(new_image)\n",
        "\n",
        "    # Testing data\n",
        "    transformed_X_test=[]\n",
        "    for j in range(len(X_test)):\n",
        "      transformed_test_images = test_transform(X_test[j])\n",
        "      new_images = np.transpose(transformed_test_images, (1, 2, 0))\n",
        "      transformed_X_test.append(new_images)\n",
        "\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n",
        "\n",
        "\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    output = Dense(3, activation='softmax')(x)  # 3 classes, so 3 output units with softmax activation\n",
        "\n",
        "    # Create a new model with modified top layers\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Callback Functions\n",
        "    es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=10)\n",
        "\n",
        "    history = model.fit(\n",
        "    np.array(transformed_X_train), y_train_encoded,\n",
        "    batch_size=b_size,\n",
        "    epochs=e_num,\n",
        "    verbose = 1,\n",
        "    callbacks=es,\n",
        "    class_weight=class_weights,\n",
        "    validation_split=0.1\n",
        "    )\n",
        "    models.append(history)\n",
        "\n",
        "    y_score = model.predict(np.array(transformed_X_test))  # Use predicted probabilities\n",
        "    y_pred_labels = np.argmax(y_score, axis=1)\n",
        "    Y_pred.append(y_pred_labels)\n",
        "\n",
        "    con0 = metrics.confusion_matrix(y_test, y_pred_labels)\n",
        "    cons.append(con0)\n",
        "\n",
        "    acc = metrics.accuracy_score(y_test, y_pred_labels)\n",
        "    accs.append(acc)\n",
        "\n",
        "    y_test_bin = label_binarize(y_test, classes=list(range(3)))  # Binarize the true labels\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "\n",
        "    for i in range(3):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    fprs.append(fpr)\n",
        "    tprs.append(tpr)\n",
        "    aucs.append(roc_auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "dPcAe30c3yh-",
        "outputId": "5f2c53fe-b2a0-4ff8-97ee-a42f7abe6f26"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Data/GZ2_E_S_I/new/performance_materials/fprs_cnn_zms_galaxy_classifier.pickle'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-37ab0c147d7b>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclassifier_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifier_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/drive/MyDrive/Data/GZ2_E_S_I/new/performance_materials/fprs_{classifier_name}_galaxy_classifier.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mfprs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/drive/MyDrive/Data/GZ2_E_S_I/new/performance_materials/tprs_{classifier_name}_galaxy_classifier.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Data/GZ2_E_S_I/new/performance_materials/fprs_cnn_zms_galaxy_classifier.pickle'"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import font_manager\n",
        "\n",
        "font_path = '/content/drive/MyDrive/Data/star_galaxy/TIMES.TTF'\n",
        "\n",
        "classifier_names = ['svm_zms', 'cnn_zms', 'cnn_transformer', 'resnet_transformer', 'vgg_transformer']\n",
        "\n",
        "for classifier_name in classifier_names:\n",
        "    with open(f'/content/drive/MyDrive/Data/GZ2_E_S_I/new/performance_materials/fprs_{classifier_name}_galaxy_classifier.pickle', 'rb') as f:\n",
        "        fprs = pickle.load(f)\n",
        "    with open(f'/content/drive/MyDrive/Data/GZ2_E_S_I/new/performance_materials/tprs_{classifier_name}_galaxy_classifier.pickle', 'rb') as f:\n",
        "        tprs = pickle.load(f)\n",
        "\n",
        "    mean_fpr = np.linspace(0, 1, 100)\n",
        "    tprs_interp = []\n",
        "\n",
        "    for i in range(len(fprs)):\n",
        "        tprs_interp.append(np.interp(mean_fpr, fprs[i][2], tprs[i][2]))\n",
        "\n",
        "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
        "    mean_auc = auc(mean_fpr, mean_tpr)\n",
        "\n",
        "    plt.plot(mean_fpr, mean_tpr, label=f'{classifier_name} (area = {mean_auc:.2f})', lw=2)\n",
        "\n",
        "if font_manager.FontProperties(fname=font_path).get_name() != 'Custom':\n",
        "    font = font_manager.FontProperties(fname=font_path)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='black', label='Random Guess')\n",
        "plt.xlabel('False Positive Rate', fontproperties=font)\n",
        "plt.ylabel('True Positive Rate', fontproperties=font)\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve', fontproperties=font)\n",
        "plt.legend(loc='lower right', prop=font_manager.FontProperties(fname=font_path))\n",
        "plt.savefig(\"/content/drive/MyDrive/Data/GZ2_E_S_I/figs/ROC_galaxy_classifier_irregular.eps\", format=\"eps\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
