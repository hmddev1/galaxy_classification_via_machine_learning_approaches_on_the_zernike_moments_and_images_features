{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Galaxy Classifiers (Spiral, Elliptical, Odd objects)\n",
        "\n",
        "Here, we developed five machine learning classifiers to identify galaxy images into Spiral, Elliptical, and Odd objects (e.g., ring, lens, disturbed, irregular, merger, and dust lane) that collected from [Galaxy Zoo 2](https://data.galaxyzoo.org/#section-7) (GZ2) cataloge. Totall of 11735 samples including 6139, 4077, 1519 for spiral, elliptical, and odd objects where used in the classifiers.\n",
        "\n",
        "- Two classifier models including supprot vector machine (SVM) and classic convolutional nueral network (CNN) have designed to use the zernike moments that extracted from original galaxies images. \n",
        "- Three classifier models including CNN-Vision Transformer, ResNet50, VGG16 have investigated to work the information of original galaxies images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import libraries:\n",
        "\n",
        "The list of requried libraries are sklearn, pandas, numpy, tensorflow, matplotlib, etc. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOYeHQ5feUyM"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import (roc_curve, roc_auc_score, auc, log_loss,\n",
        "                             precision_score, recall_score, f1_score,\n",
        "                             accuracy_score, classification_report,\n",
        "                             ConfusionMatrixDisplay, confusion_matrix)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from tensorflow.keras.layers import (Dense, Dropout,BatchNormalization, Input, Conv1D, Flatten,\n",
        "                             MaxPooling1D)\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "from skimage.measure import label\n",
        "from skimage.transform import resize\n",
        "from skimage.segmentation import slic, mark_boundaries\n",
        "from skimage.color import label2rgb\n",
        "\n",
        "#Scikit_learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (roc_curve, roc_auc_score, auc, log_loss,\n",
        "                             precision_score, recall_score, f1_score,\n",
        "                             accuracy_score, classification_report,\n",
        "                             ConfusionMatrixDisplay, confusion_matrix)\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import label_binarize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Using the **\"watershed\"** algorithm, we cropped the centeral galaxy features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def seg_1(img):\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV +cv2.THRESH_OTSU, cv2.THRESH_TRUNC)\n",
        "  kernel = np.ones((3,3),np.uint8)\n",
        "  opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
        "  sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
        "  dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
        "  ret, aa = cv2.threshold(dist_transform,0.01*dist_transform.max(),255,0)\n",
        "  x,y=np.where(aa==0)\n",
        "  im=thresh.copy()*0\n",
        "  im[x,y]=1\n",
        "  im1 = label(im)\n",
        "  f=im1[212,212]\n",
        "  x,y=np.where(im1==f)\n",
        "  imd=im1.copy()*0\n",
        "  imd[x,y]=1\n",
        "  return x,y,imd\n",
        "\n",
        "\n",
        "def seg_2(img):\n",
        "  segments = slic(img,n_segments=25,compactness=10)\n",
        "  ss=label2rgb(segments,img,kind = 'avg')\n",
        "  aa=ss[:,:,2]\n",
        "  f=aa[212,212]\n",
        "  x,y=np.where(aa==f)\n",
        "  dd=aa.copy()*0\n",
        "  dd[x,y]=1\n",
        "  return x,y,dd\n",
        "\n",
        "\n",
        "def seg_3(img,x,y):\n",
        "    x1=np.min(x)-20\n",
        "    x2=np.max(x)+20\n",
        "    y1=np.min(y)-20\n",
        "    y2=np.max(y)+20\n",
        "    imn=img[x1:x2,y1:y2]\n",
        "    newsize=(x2-x1,x2-x1)\n",
        "    resized_im =resize(imn,newsize)\n",
        "    xx = x1 + (x2 - x1) / 2 - 212\n",
        "    yy = y1 + (y2 - y1) / 2 - 212\n",
        "    return xx, yy,resized_im\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_path = r'/path/to/repository/Data/galaxy/image/spiral'\n",
        "\n",
        "image_files = [os.path.join(image_path, filename) for filename in os.listdir(image_path) if filename.endswith('.jpg')]\n",
        "cropped_imgs = []\n",
        "cropped_image_count = 0\n",
        "\n",
        "for im in image_files:\n",
        "    xx=100\n",
        "    yy=100\n",
        "    img = cv2.imread(im)\n",
        "    x, y, imd = seg_1(img)  \n",
        "\n",
        "    if np.min(x)>20 and np.min(y)>20 and np.max(y)<212*2-20 and np.max(x)<212*2-20:\n",
        "        xx,yy,resized_im=seg_3(img,x,y)\n",
        "        if (np.abs(xx) >= 30) and (np.abs(yy) >= 30):\n",
        "            x, y, dd = seg_2(img)\n",
        "            xx,yy,resized_im=seg_3(img,x,y)\n",
        "    else: \n",
        "        x, y, dd = seg_2(img) \n",
        "        if np.min(x)>20 and np.min(y)>20 and np.max(y)<212*2-20 and np.max(x)<212*2-20:\n",
        "            xx,yy,resized_im=seg_3(img,x,y)      \n",
        "            # print(xx,yy)\n",
        "    if (np.abs(xx) < 30) and (np.abs(yy) < 30):\n",
        "            ms = np.shape(resized_im)\n",
        "            if ms[0] < 150:\n",
        "                crop_img = np.array(resize(resized_im, (150, 150)))\n",
        "            elif (ms[0] < 250) and (ms[0] >= 150):\n",
        "                crop_img = np.array(resize(resized_im, (250, 250)))\n",
        "            elif (ms[0] < 350) and (ms[0] >= 250):\n",
        "                crop_img = np.array(resize(resized_im, (350, 350)))\n",
        "            elif ms[0] >= 350:\n",
        "                crop_img = np.array(resize(resized_im, (450, 450)))\n",
        "                                                                  \n",
        "            arr_img = np.array(crop_img)\n",
        "            cropped_imgs.append(arr_img)\n",
        "\n",
        "            cropped_image_count += 1\n",
        "\n",
        "\n",
        "print(f\"Total number of cropped images: {cropped_image_count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Two classifier models based on Zernike moments (ZMs):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute the ZMs:\n",
        "\n",
        "##### First we need to compute ZMs for galaxy and non-galaxy images. The ZEMO python package [https://pypi.org/project/ZEMO/] [https://github.com/hmddev1/ZEMO] can be used to compute Zernike moments (ZMs) for images. This package was described in the research paper [[IAJJ](https://ijaa.du.ac.ir/article_374_ad45803d737b0a7d4fc554a244229df6.pdf)].\n",
        "\n",
        "*Note: The galaxy and non-galaxy images are in RGB format. Here, we used the R channel of images. The size of original Galaxy Zoo 2 images is (424, 424) pixels, while we resized them to (200, 200) pixels. To compute ZMs we set the maximum order number $P{max} = 45$.* "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ZEMO import zemo\n",
        "import cv2\n",
        "\n",
        "def calculate_zernike_moments(data_dir, image_size, zernike_order):\n",
        "        \n",
        "        ZBFSTR = zemo.zernike_bf(image_size, zernike_order, 1)\n",
        "        \n",
        "        image_files = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir) if filename.endswith('.jpg')]\n",
        "        \n",
        "        zernike_moments = []\n",
        "    \n",
        "        for img_path in image_files:\n",
        "            image = cv2.imread(img_path)\n",
        "            resized_image = cv2.resize(image, (image_size,image_size))\n",
        "            im = resized_image[:, :, 0]\n",
        "            Z = np.abs(zemo.zernike_mom(np.array(im), ZBFSTR))\n",
        "            zernike_moments.append(Z)\n",
        "        \n",
        "        df = pd.DataFrame(zernike_moments)\n",
        "    \n",
        "        return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Download **Data** files from [here](https://drive.google.com/file/d/1wxmYQ8qpgaVDuD3kTeBrZlyny0IBA9wn/view?usp=drive_link)\n",
        "\n",
        "- The directoies of Spiral, Elliptical, Odd objects images:\n",
        "\n",
        "        - Spiral: /repository/Data/galaxy/image/cropped_spiral\n",
        "        - Elliptical: /repository/Data/galaxy/image/cropped_elliptical\n",
        "        - odd objects: /repository/Data/galaxy/image/cropped_odd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spath = r'/path/to/repository/Data/galaxy/image/cropped_spiral' \n",
        "epath = r'/path/to/repository/Data/galaxy/image/cropped_elliptical' \n",
        "opath = r'/path/to/repository/Data/galaxy/image/cropped_odd' \n",
        "\n",
        "# Defult image size and zernike order. \n",
        "image_size = 200\n",
        "zernike_order = 45\n",
        "\n",
        "spiral_zm_df = calculate_zernike_moments(spath, image_size, zernike_order)\n",
        "spiral_zm_df.to_csv('/path/to/repository/Data/galaxy/ZMs/spiral_zms.csv')\n",
        "\n",
        "elliptical_zm_df = calculate_zernike_moments(epath, image_size, zernike_order)\n",
        "elliptical_zm_df.to_csv('/path/to/repository/Data/galaxy/ZMs/elliptical_zms.csv')\n",
        "\n",
        "odd_zm_df = calculate_zernike_moments(opath, image_size, zernike_order)\n",
        "odd_zm_df.to_csv('/path/to/repository/Data/galaxy/ZMs/odd_zms.csv')\n",
        "\n",
        "np.shape(spiral_zm_df), np.shape(elliptical_zm_df), np.shape(odd_zm_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "*Note: Computing of ZMs for above mentioned galaxy and non-galaxy images are slightly consuming time. So, we upladed the zernike moments of both classes in this repository.*\n",
        "\n",
        "**To load the ZMs please use:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7HrfV4O2p5o"
      },
      "outputs": [],
      "source": [
        "spiral_data = pd.read_csv('/path/to/repository/Data/galaxy/ZMs/spiral_zms.csv')\n",
        "elliptical_data = pd.read_csv('/path/to/repository/Data/galaxy/ZMs/elliptical_zms.csv')\n",
        "odd_data = pd.read_csv('/path/to/repository/Data/galaxy/ZMs/odd_zms.csv')\n",
        "\n",
        "spiral_data.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
        "elliptical_data.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
        "odd_data.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
        "\n",
        "all_zm_data = np.concatenate([spiral_data, elliptical_data, odd_data])\n",
        "np.shape(all_zm_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We use **\"0\"** for spiral class labels, **\"1\"** for elliptical class labels, and **\"2\"** for odd objects class labels.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fDMPYw78c46",
        "outputId": "51ceaafe-3161-49c8-89c2-27b46403b04e"
      },
      "outputs": [],
      "source": [
        "spiral_label = [0] * len(spiral_data)\n",
        "elliptical_label = [1] * len(elliptical_data)\n",
        "odd_label = [2] * len(odd_data)\n",
        "\n",
        "all_labels = np.concatenate([spiral_label, elliptical_label, odd_label])\n",
        "len(all_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **SVM + ZMs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We split the data set into 75 percent traning set and 25 percent test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(all_zm_data, all_labels, np.arange(len(all_labels)), \n",
        "                                                                                 test_size=0.25, shuffle=True, random_state=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Since, the galaxy classifiers are unbalance class models, so we used the class weight in the program:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_weights = {0: len(all_zm_data) / (3*len(spiral_data)), 1: len(all_zm_data) / (3*len(elliptical_data)), 2: len(all_zm_data) / (3*len(odd_data))}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The **SVM** model uses radial base kernel (rbf), C = 1.5, and gamma = 'scale' to fit the model on the training set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SVC(kernel='rbf', probability=True, C=1.5, gamma='scale',class_weight=class_weights)\n",
        "gz2_training_model = model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Now, we apply the test set to examine the classification algorithm. Using the predicted label by the machine on original labels, we compute the elements of the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "con = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(con)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- To compare the performace of classifier with the random classifier, we calculate the **reciver operation charecterstic curve (ROC curve)**. The **area under the curve (AUC)** shows the probability of True positive rates of the classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_score = gz2_training_model.predict_proba(X_test)  # Use predicted probabilities for ROC curve\n",
        "y_test_bin = label_binarize(y_test, classes=list(range(3)))  # Binarize the true labels\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(3):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "class_names = ['Spiral', 'Elliptical', 'Odd objects']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "\n",
        "for j in range(3):  # Iterate through each class\n",
        "    tprs_interp = []\n",
        "    for i in range(len(fpr)):\n",
        "        tprs_interp.append(np.interp(mean_fpr, fpr[i][j], tpr[i][j]))\n",
        "\n",
        "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
        "    mean_auc = np.trapz(mean_tpr, mean_fpr)\n",
        "\n",
        "    ax.plot(mean_fpr, mean_tpr, label=f'{class_names[j]} (area = {mean_auc:.2f})', lw=2)\n",
        "\n",
        "ax.plot([0, 1], [0, 1], linestyle='--', color='black', label='Random Guess')\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title(f'Receiver Operating Characteristic (ROC) Curve')\n",
        "ax.legend(loc='lower right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- To measure the performance metrics of classifier, we compute **(Recall, Precision, f1_score, Accuracy, TSS(True Skill Statistic))**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "recall = recall_score(y_test, y_pred, average= 'weighted')\n",
        "precision = precision_score(y_test, y_pred, average= 'weighted')\n",
        "f1_score = f1_score(y_test, y_pred, average= 'weighted')\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "tss=(tp/(tp+fn))-(fp/(fp+tn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Recall:\", recall)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1_score:\", f1_score)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"TSS:\", tss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **1D_CNN + ZMs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We use **\"0\"** for spiral class labels, **\"1\"** for elliptical class labels, and **\"2\"** for odd objects class labels.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spiral_label = [0] * len(spiral_data)\n",
        "elliptical_label = [1] * len(elliptical_data)\n",
        "odd_label = [2] * len(odd_data)\n",
        "\n",
        "all_labels = np.concatenate([spiral_label, elliptical_label, odd_label])\n",
        "len(all_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We split the data set into 75 percent traning set and 25 percent test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(all_zm_data, all_labels, np.arange(len(all_labels)), \n",
        "                                                                                 test_size=0.25, shuffle=True, random_state=None)\n",
        "\n",
        "y_train_encoded = to_categorical(y_train, num_classes=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Since, the galaxy classifiers are unbalance class models, so we used the class weight in the program:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_weights = {0: len(all_zm_data) / (3*len(spiral_data)), 1: len(all_zm_data) / (3*len(elliptical_data)), 2: len(all_zm_data) / (3*len(odd_data))}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Due to one dimentional structure of ZMs, we used one dimentional achitecture of CNN: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# input value\n",
        "x = Input(shape=(all_zm_data.shape[1],1))\n",
        "\n",
        "#hidden layers\n",
        "c0 = Conv1D(256, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "b0 = BatchNormalization()(c0)\n",
        "m0 = MaxPooling1D(pool_size=2)(b0)\n",
        "d0 = Dropout(0.1)(m0)\n",
        "\n",
        "c1 = Conv1D(128, kernel_size=3, strides=2, padding=\"same\")(d0)\n",
        "b1 = BatchNormalization()(c1)\n",
        "m1 = MaxPooling1D(pool_size=2)(b1)\n",
        "d1 = Dropout(0.1)(m1)\n",
        "\n",
        "c2 = Conv1D(64, kernel_size=3, strides=2, padding=\"same\")(d1)\n",
        "b2 = BatchNormalization()(c2)\n",
        "m2 = MaxPooling1D(pool_size=2)(b2)\n",
        "d2 = Dropout(0.1)(m2)\n",
        "\n",
        "f = Flatten()(d2)\n",
        "\n",
        "# output\n",
        "de0 = Dense(64, activation='relu')(f)\n",
        "de1 = Dense(32, activation='relu')(de0)\n",
        "de2 = Dense(2, activation='softmax')(de1)\n",
        "\n",
        "model = Model(inputs=x, outputs=de2, name=\"cnn_zm_45_galaxy_nonegalaxy\")\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The **1D_CNN** model uses EarlyStopping as callback function, batch size = 64, and number of epochs = 30 to fit the model on the training set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Callback Function\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "b_size = 64\n",
        "e_num = 30\n",
        "\n",
        "history = model.fit(\n",
        "X_train, y_train_encoded,\n",
        "batch_size=b_size,\n",
        "epochs=e_num,\n",
        "class_weight=class_weights,\n",
        "verbose = 1,\n",
        "callbacks=es,\n",
        "validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Now, we apply the test set to examine the classification algorithm. Using the predicted label by the machine on original labels, we compute the elements of the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "con = metrics.confusion_matrix(y_test, y_pred_labels)\n",
        "print(con)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- To compare the performace of classifier with the random classifier, we calculate the **reciver operation charecterstic curve (ROC curve)**. The **area under the curve (AUC)** shows the probability of True positive rates of the classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_score = gz2_training_model.predict_proba(X_test)  # Use predicted probabilities for ROC curve\n",
        "y_test_bin = label_binarize(y_test, classes=list(range(3)))  # Binarize the true labels\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(3):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "class_names = ['Spiral', 'Elliptical', 'Odd objects']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "\n",
        "for j in range(3):  # Iterate through each class\n",
        "    tprs_interp = []\n",
        "    for i in range(len(fpr)):\n",
        "        tprs_interp.append(np.interp(mean_fpr, fpr[i][j], tpr[i][j]))\n",
        "\n",
        "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
        "    mean_auc = np.trapz(mean_tpr, mean_fpr)\n",
        "\n",
        "    ax.plot(mean_fpr, mean_tpr, label=f'{class_names[j]} (area = {mean_auc:.2f})', lw=2)\n",
        "\n",
        "ax.plot([0, 1], [0, 1], linestyle='--', color='black', label='Random Guess')\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title(f'Receiver Operating Characteristic (ROC) Curve')\n",
        "ax.legend(loc='lower right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- To measure the performance metrics of classifier, we compute **(Recall, Precision, f1_score, Accuracy, TSS(True Skill Statistic))**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "recall = recall_score(y_test, y_pred, average= 'weighted')\n",
        "precision = precision_score(y_test, y_pred, average= 'weighted')\n",
        "f1_score = f1_score(y_test, y_pred, average= 'weighted')\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "tss=(tp/(tp+fn))-(fp/(fp+tn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Recall:\", recall)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1_score:\", f1_score)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"TSS:\", tss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Three classifier models based on the original images:\n",
        "  \n",
        "- (Vision Transformer used as data augmentation tool on the Galaxy and Non-Galaxy images.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import the requried libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import packages \n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import (Dense, Dropout, Input,Conv2D, Flatten,\n",
        "                             MaxPooling2D,BatchNormalization)\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import ResNet50, VGG16\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "#Torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- To read the images of each class and convert to Pillow images we used the following function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_galaxy_images(data_dir, target_size):\n",
        "        \n",
        "        \"\"\"\n",
        "        Loads, resizes, and processes all JPG images from the specified directory.\n",
        "\n",
        "        Parameters:\n",
        "        data_dir (str): The directory containing the JPG images to be processed.\n",
        "        target_size (tuple): The target size for resizing the images, specified as (width, height).\n",
        "\n",
        "        Returns:\n",
        "        list: A list of PIL Image objects, each representing a resized and processed image.\n",
        "\n",
        "        The function performs the following steps:\n",
        "        1. Lists all JPG image files in the specified directory.\n",
        "        2. Reads each image using OpenCV.\n",
        "        3. Resizes each image to the specified target size.\n",
        "        4. Scales the pixel values and converts the image to a format compatible with PIL.\n",
        "        5. Converts each resized image to a PIL Image object.\n",
        "        6. Appends each PIL Image object to a list.\n",
        "        7. Returns the list of PIL Image objects.\n",
        "        \"\"\"\n",
        "\n",
        "        all_images = []\n",
        "\n",
        "        file_path = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir) if filename.endswith('.jpg')]\n",
        "\n",
        "        for img in file_path:\n",
        "            image = cv2.imread(img)\n",
        "            resized_images=cv2.resize(image, target_size)\n",
        "            resized_images = (resized_images * 255).astype(np.uint8)\n",
        "            pil_images = Image.fromarray(resized_images)\n",
        "            all_images.append(pil_images)\n",
        "\n",
        "        return all_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The directoies of Spiral, Elliptical, Odd objectss images:\n",
        "\n",
        "        - Spiral: /repository/Data/galaxy/image/cropped_spiral\n",
        "        - Elliptical: /repository/Data/galaxy/image/cropped_elliptical\n",
        "        - odd objects: /repository/Data/galaxy/image/cropped_odd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sp_dir = '/path/to/repository/Data/galaxy/image/cropped_spiral'\n",
        "el_dir = '/path/to/repository/Data/galaxy/image/cropped_elliptical'\n",
        "odd_dir = '/path/to/repository/Data/galaxy/image/cropped_odd'\n",
        "\n",
        "image_size = 200\n",
        "\n",
        "sp_img = load_galaxy_images(sp_dir, target_size=(image_size,image_size))\n",
        "el_img = load_galaxy_images(el_dir, target_size=(image_size,image_size))\n",
        "odd_img = load_galaxy_images(odd_dir, target_size=(image_size,image_size))\n",
        "\n",
        "all_data = np.concatenate([sp_img, el_img, odd_img])\n",
        "np.shape(all_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We define the **vision transformer** for both training and testing data sets: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# transforms for training data\n",
        "train_transform = transforms.Compose([transforms.CenterCrop(image_size),\n",
        "                                      transforms.RandomRotation(90),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.RandomVerticalFlip(),\n",
        "                                      transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0), ratio=(0.99, 1.01)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                                      ])\n",
        "\n",
        "\n",
        "# transforms for test data\n",
        "test_transform = transforms.Compose([transforms.CenterCrop(image_size),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                                      ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **CNN + vision transformer + original images**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We use **\"0\"** for spiral class labels, **\"1\"** for elliptical class labels, and **\"2\"** for odd objects class labels.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_s = [0] * len(sp_img)\n",
        "label_e = [1] * len(el_img)\n",
        "label_o = [2] * len(odd_img)\n",
        "\n",
        "all_labels = np.concatenate([label_s, label_e, label_o])\n",
        "len(all_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We split the data set into 75 percent traning set and 25 percent test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(all_data, all_labels, np.arange(len(all_labels)), \n",
        "                                                                                 test_size=0.25, shuffle=True, random_state=None)\n",
        "\n",
        "y_train_encoded = to_categorical(y_train, num_classes=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We apply the vision transformer for both training and testing samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformer for training data\n",
        "transformed_X_train=[]\n",
        "for i in range(len(X_train)):\n",
        "  transformed_train_images = train_transform(X_train[i])\n",
        "  new_image = np.transpose(transformed_train_images, (1, 2, 0))\n",
        "  transformed_X_train.append(new_image)\n",
        "\n",
        "# Transformer for testing data\n",
        "transformed_X_test=[]\n",
        "for j in range(len(X_test)):\n",
        "  transformed_test_images = test_transform(X_test[j])\n",
        "  new_images = np.transpose(transformed_test_images, (1, 2, 0))\n",
        "  transformed_X_test.append(new_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Since, the galaxy classifiers are unbalance class models, so we used the class weight in the program:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_weights = {0: len(all_data) / (3*len(sp_img)), 1: len(all_data) / (3*len(el_img)), 2: len(all_data) / (3*len(odd_img))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# input\n",
        "x = Input(shape=(image_size,image_size,3))\n",
        "\n",
        "#hidden layers\n",
        "c0 = Conv2D(256, kernel_size=(3,3), strides=(1,1), padding=\"same\")(x)\n",
        "b0 = BatchNormalization()(c0)\n",
        "m0 = MaxPooling2D(pool_size=(2, 2))(b0)\n",
        "d0 = Dropout(0.1)(m0)\n",
        "\n",
        "c1 = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding=\"same\")(m0)\n",
        "b1 = BatchNormalization()(c1)\n",
        "m1 = MaxPooling2D(pool_size=(2, 2))(b1)\n",
        "d1 = Dropout(0.1)(m1)\n",
        "\n",
        "c2 = Conv2D(64, kernel_size=(3,3), strides=(1,1), padding=\"same\")(m1)\n",
        "b2 = BatchNormalization()(c2)\n",
        "m2 = MaxPooling2D(pool_size=(2, 2))(b2)\n",
        "d2 = Dropout(0.1)(m2)\n",
        "\n",
        "f = Flatten()(m2)\n",
        "\n",
        "de0 = Dense(64, activation='relu')(f)\n",
        "de1 = Dense(32, activation='relu')(de0)\n",
        "de2 = Dense(3, activation='softmax')(de1)\n",
        "\n",
        "model = Model(inputs=x, outputs=de2, name=\"cnn_transformer_galaxy_nonegalaxy\")\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The **CNN** model uses EarlyStopping as callback function, batch size = 64, and number of epochs = 30 to fit the model on the training set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "b_size =64\n",
        "e_num = 30\n",
        "\n",
        "# Callback Functions\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "history = model.fit(\n",
        "np.array(transformed_X_train), y_train_encoded,\n",
        "batch_size=b_size,\n",
        "epochs=e_num,\n",
        "verbose = 1,\n",
        "class_weight=class_weights,\n",
        "callbacks=es,\n",
        "validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Now, we apply the test set to examine the classification algorithm. Using the predicted label by the machine on original labels, we compute the elements of the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model.predict(np.array(transformed_X_test))\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "con = metrics.confusion_matrix(y_test, y_pred_labels)\n",
        "print(con)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- To compare the performace of classifier with the random classifier, we calculate the **reciver operation charecterstic curve (ROC curve)**. The **area under the curve (AUC)** shows the probability of True positive rates of the classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_score = gz2_training_model.predict_proba(X_test)  # Use predicted probabilities for ROC curve\n",
        "y_test_bin = label_binarize(y_test, classes=list(range(3)))  # Binarize the true labels\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(3):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "class_names = ['Spiral', 'Elliptical', 'Odd objects']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "\n",
        "for j in range(3):  # Iterate through each class\n",
        "    tprs_interp = []\n",
        "    for i in range(len(fpr)):\n",
        "        tprs_interp.append(np.interp(mean_fpr, fpr[i][j], tpr[i][j]))\n",
        "\n",
        "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
        "    mean_auc = np.trapz(mean_tpr, mean_fpr)\n",
        "\n",
        "    ax.plot(mean_fpr, mean_tpr, label=f'{class_names[j]} (area = {mean_auc:.2f})', lw=2)\n",
        "\n",
        "ax.plot([0, 1], [0, 1], linestyle='--', color='black', label='Random Guess')\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title(f'Receiver Operating Characteristic (ROC) Curve')\n",
        "ax.legend(loc='lower right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- To measure the performance metrics of classifier, we compute **(Recall, Precision, f1_score, Accuracy, TSS(True Skill Statistic))**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "recall = recall_score(y_test, y_pred, average= 'weighted')\n",
        "precision = precision_score(y_test, y_pred, average= 'weighted')\n",
        "f1_score = f1_score(y_test, y_pred, average= 'weighted')\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "tss=(tp/(tp+fn))-(fp/(fp+tn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Recall:\", recall)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1_score:\", f1_score)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"TSS:\", tss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **ResNet50 + vision transformer + original images**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We use **\"0\"** for spiral class labels, **\"1\"** for elliptical class labels, and **\"2\"** for odd objects class labels.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_s = [0] * len(sp_img)\n",
        "label_e = [1] * len(el_img)\n",
        "label_o = [2] * len(odd_img)\n",
        "\n",
        "all_labels = np.concatenate([label_s, label_e, label_o])\n",
        "len(all_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We split the data set into 75 percent traning set and 25 percent test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(all_data, all_labels, np.arange(len(all_labels)), \n",
        "                                                                                 test_size=0.25, shuffle=True, random_state=None)\n",
        "\n",
        "y_train_encoded = to_categorical(y_train, num_classes=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We apply the vision transformer for both training and testing samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformer for training data\n",
        "transformed_X_train=[]\n",
        "for i in range(len(X_train)):\n",
        "  transformed_train_images = train_transform(X_train[i])\n",
        "  new_image = np.transpose(transformed_train_images, (1, 2, 0))\n",
        "  transformed_X_train.append(new_image)\n",
        "\n",
        "# Transformer for testing data\n",
        "transformed_X_test=[]\n",
        "for j in range(len(X_test)):\n",
        "  transformed_test_images = test_transform(X_test[j])\n",
        "  new_images = np.transpose(transformed_test_images, (1, 2, 0))\n",
        "  transformed_X_test.append(new_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Since, the galaxy classifiers are unbalance class models, so we used the class weight in the program:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_weights = {0: len(all_data) / (3*len(sp_img)), 1: len(all_data) / (3*len(el_img)), 2: len(all_data) / (3*len(odd_img))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Defining the pretrained ResNet50\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(64, activation='relu')(x)  # The custom layers\n",
        "output = Dense(2, activation='softmax')(x)  \n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "history = model.fit(\n",
        "np.array(transformed_X_train), y_train_encoded,\n",
        "batch_size=b_size,\n",
        "epochs=e_num,\n",
        "verbose = 1,\n",
        "callbacks=es,\n",
        "class_weight=class_weights,\n",
        "validation_split=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Now, we apply the test set to examine the classification algorithm. Using the predicted label by the machine on original labels, we compute the elements of the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model.predict(np.array(transformed_X_test))\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "con = metrics.confusion_matrix(y_test, y_pred_labels)\n",
        "print(con)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- To compare the performace of classifier with the random classifier, we calculate the **reciver operation charecterstic curve (ROC curve)**. The **area under the curve (AUC)** shows the probability of True positive rates of the classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_score = gz2_training_model.predict_proba(X_test)  # Use predicted probabilities for ROC curve\n",
        "y_test_bin = label_binarize(y_test, classes=list(range(3)))  # Binarize the true labels\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(3):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "class_names = ['Spiral', 'Elliptical', 'Odd objects']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "\n",
        "for j in range(3):  # Iterate through each class\n",
        "    tprs_interp = []\n",
        "    for i in range(len(fpr)):\n",
        "        tprs_interp.append(np.interp(mean_fpr, fpr[i][j], tpr[i][j]))\n",
        "\n",
        "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
        "    mean_auc = np.trapz(mean_tpr, mean_fpr)\n",
        "\n",
        "    ax.plot(mean_fpr, mean_tpr, label=f'{class_names[j]} (area = {mean_auc:.2f})', lw=2)\n",
        "\n",
        "ax.plot([0, 1], [0, 1], linestyle='--', color='black', label='Random Guess')\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title(f'Receiver Operating Characteristic (ROC) Curve')\n",
        "ax.legend(loc='lower right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- To measure the performance metrics of classifier, we compute **(Recall, Precision, f1_score, Accuracy, TSS(True Skill Statistic))**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "recall = recall_score(y_test, y_pred, average= 'weighted')\n",
        "precision = precision_score(y_test, y_pred, average= 'weighted')\n",
        "f1_score = f1_score(y_test, y_pred, average= 'weighted')\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "tss=(tp/(tp+fn))-(fp/(fp+tn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Recall:\", recall)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1_score:\", f1_score)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"TSS:\", tss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **VGG16 + vision transformer + original images**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We use **\"0\"** for spiral class labels, **\"1\"** for elliptical class labels, and **\"2\"** for odd objects class labels.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_s = [0] * len(sp_img)\n",
        "label_e = [1] * len(el_img)\n",
        "label_o = [2] * len(odd_img)\n",
        "\n",
        "all_labels = np.concatenate([label_s, label_e, label_o])\n",
        "len(all_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We split the data set into 75 percent traning set and 25 percent test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(all_data, all_labels, np.arange(len(all_labels)), \n",
        "                                                                                 test_size=0.25, shuffle=True, random_state=None)\n",
        "\n",
        "y_train_encoded = to_categorical(y_train, num_classes=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We apply the vision transformer for both training and testing samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformer for training data\n",
        "transformed_X_train=[]\n",
        "for i in range(len(X_train)):\n",
        "  transformed_train_images = train_transform(X_train[i])\n",
        "  new_image = np.transpose(transformed_train_images, (1, 2, 0))\n",
        "  transformed_X_train.append(new_image)\n",
        "\n",
        "# Transformer for testing data\n",
        "transformed_X_test=[]\n",
        "for j in range(len(X_test)):\n",
        "  transformed_test_images = test_transform(X_test[j])\n",
        "  new_images = np.transpose(transformed_test_images, (1, 2, 0))\n",
        "  transformed_X_test.append(new_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Since, the galaxy classifiers are unbalance class models, so we used the class weight in the program:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_weights = {0: len(all_data) / (3*len(sp_img)), 1: len(all_data) / (3*len(el_img)), 2: len(all_data) / (3*len(odd_img))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Defining the pretrained ResNet50\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(64, activation='relu')(x)  # The custom layers\n",
        "output = Dense(2, activation='softmax')(x)  \n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "history = model.fit(\n",
        "np.array(transformed_X_train), y_train_encoded,\n",
        "batch_size=b_size,\n",
        "epochs=e_num,\n",
        "verbose = 1,\n",
        "callbacks=es,\n",
        "class_weight=class_weights,\n",
        "validation_split=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Now, we apply the test set to examine the classification algorithm. Using the predicted label by the machine on original labels, we compute the elements of the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model.predict(np.array(transformed_X_test))\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "con = metrics.confusion_matrix(y_test, y_pred_labels)\n",
        "print(con)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- To compare the performace of classifier with the random classifier, we calculate the **reciver operation charecterstic curve (ROC curve)**. The **area under the curve (AUC)** shows the probability of True positive rates of the classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_score = gz2_training_model.predict_proba(X_test)  # Use predicted probabilities for ROC curve\n",
        "y_test_bin = label_binarize(y_test, classes=list(range(3)))  # Binarize the true labels\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(3):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "class_names = ['Spiral', 'Elliptical', 'Odd objects']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "\n",
        "for j in range(3):  # Iterate through each class\n",
        "    tprs_interp = []\n",
        "    for i in range(len(fpr)):\n",
        "        tprs_interp.append(np.interp(mean_fpr, fpr[i][j], tpr[i][j]))\n",
        "\n",
        "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
        "    mean_auc = np.trapz(mean_tpr, mean_fpr)\n",
        "\n",
        "    ax.plot(mean_fpr, mean_tpr, label=f'{class_names[j]} (area = {mean_auc:.2f})', lw=2)\n",
        "\n",
        "ax.plot([0, 1], [0, 1], linestyle='--', color='black', label='Random Guess')\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title(f'Receiver Operating Characteristic (ROC) Curve')\n",
        "ax.legend(loc='lower right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- To measure the performance metrics of classifier, we compute **(Recall, Precision, f1_score, Accuracy, TSS(True Skill Statistic))**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "recall = recall_score(y_test, y_pred, average= 'weighted')\n",
        "precision = precision_score(y_test, y_pred, average= 'weighted')\n",
        "f1_score = f1_score(y_test, y_pred, average= 'weighted')\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "tss=(tp/(tp+fn))-(fp/(fp+tn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Recall:\", recall)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1_score:\", f1_score)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"TSS:\", tss)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
