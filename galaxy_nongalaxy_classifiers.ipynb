{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Galaxy and Non-Galaxy Classifiers:\n",
        "\n",
        "Here, we developed five machine learning classifiers for [Galaxy Zoo 2](https://data.galaxyzoo.org/#section-7) (GZ2) cataloge images to recognize the galaxy images from non-galaxy images. These five classification models use the morphological and shape information. We applied the threshold based tasks (features or disk fraction, edge-on no fraction, spiral fraction, smooth fraction, completely round fraction, odd no fraction, and odd yes fraction) to collect 780 galaxy sample images. Also, we used threshold tasks (star or artifact fraction) to collect 545 non-galaxy images. \n",
        "\n",
        "- Two classifier models including supprot vector machine (SVM) and classic 1D-convolutional nueral network (1D-CNN) have designed to use the Zernike moments (ZMs) that extracted from original galaxy and non-galaxy images. \n",
        "- Three classifier models including CNN-Vision Transformer, ResNet50, VGG16 have investigated to work the information of original galaxy and non-galaxy images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import libraries:\n",
        "\n",
        "The list of requried libraries are sklearn, pandas, numpy, tensorflow, matplotlib, etc. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qma9b0d_c5b1"
      },
      "outputs": [],
      "source": [
        "#Import packages\n",
        "\n",
        "import os\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from tensorflow.keras.layers import (Dense, Dropout,BatchNormalization, Input, Conv1D, Flatten,\n",
        "                             MaxPooling1D)\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "#Scikit_learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (accuracy_score, classification_report,\n",
        "                             ConfusionMatrixDisplay, confusion_matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download galaxy and non-galaxy images:\n",
        "\n",
        "        - Galaxy: \n",
        "        - Non-Galxy:\n",
        "\n",
        "To read images please apply:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def load_images(data_dir):\n",
        "\n",
        "#         image_files = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir) if filename.endswith('.jpg')]\n",
        "\n",
        "#         return image_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# path_galaxy = r'/path/to/your/directory/galaxy' \n",
        "# path_nongalaxy = r'/path/to/your/directory/nongalaxy' \n",
        "\n",
        "# # function \n",
        "\n",
        "# image_files = [os.path.join(path, filename) for filename in os.listdir(path) if filename.endswith('.jpg')]\n",
        "# len(image_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Two classifier models based on Zernike moments (ZMs):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute the ZMs:\n",
        "\n",
        "##### First we need to compute ZMs for galaxy and non-galaxy images. The ZEMO python package [https://pypi.org/project/ZEMO/] [https://github.com/hmddev1/ZEMO] can be used to compute Zernike moments (ZMs) for images. This package was described in the research paper [[IAJJ](https://ijaa.du.ac.ir/article_374_ad45803d737b0a7d4fc554a244229df6.pdf)].\n",
        "\n",
        "*Note: The galaxy and non-galaxy images are in RGB format. Here, we used the R channel of images. The size of original Galaxy Zoo 2 images is (424, 424) pixels, while we resized them to (200, 200) pixels. To compute ZMs we set the maximum order number $P{max} = 45$.* "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# image_size = 200\n",
        "# zernike_order = 45\n",
        "\n",
        "# ZBFSTR = zemo.zernike_bf(image_size, zernike_order, 1)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ZEMO import zemo\n",
        "import cv2\n",
        "\n",
        "def calculate_zernike_moments(data_dir, image_size, zernike_order):\n",
        "        \n",
        "        ZBFSTR = zemo.zernike_bf(image_size, zernike_order, 1)\n",
        "        \n",
        "        image_files = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir) if filename.endswith('.jpg')]\n",
        "        \n",
        "        zernike_moments = []\n",
        "    \n",
        "        for img_path in image_files:\n",
        "            image = cv2.imread(img_path)\n",
        "            resized_image = cv2.resize(image, (image_size,image_size))\n",
        "            im = resized_image[:, :, 0]\n",
        "            Z = np.abs(zemo.zernike_mom(np.array(im), ZBFSTR))\n",
        "            zernike_moments.append(Z)\n",
        "        \n",
        "        df = pd.DataFrame(zernike_moments)\n",
        "    \n",
        "        return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "galaxy_path = r'/path/to/your/directory/galaxy' \n",
        "nongalaxy_path = r'/path/to/your/directory/nongalaxy' \n",
        "\n",
        "image_size = 200\n",
        "zernike_order = 45\n",
        "\n",
        "galaxy_zm_df = calculate_zernike_moments(galaxy_path, image_size, zernike_order)\n",
        "galaxy_zm_df.to_csv('/path/to/your/directory/galaxy_zms.csv')\n",
        "\n",
        "nongalaxy_zm_df = calculate_zernike_moments(nongalaxy_path, image_size, zernike_order)\n",
        "nongalaxy_zm_df.to_csv('/path/to/your/directory/galaxy_zms.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ZZ = []\n",
        "\n",
        "# for img_path in image_files:\n",
        "#     image = cv2.imread(img_path)\n",
        "#     resized_image = cv2.resize(image, (image_size, image_size))\n",
        "#     im = resized_image[:,:,0]\n",
        "#     Z = np.abs(zemo.zernike_mom(np.array(im), ZBFSTR))\n",
        "#     ZZ.append(Z)\n",
        "\n",
        "\n",
        "\n",
        "# # Save the ZMs as data frame\n",
        "# df = pd.DataFrame(ZZ)\n",
        "# df.to_csv('/path/to/your/directory/galaxy_zms.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "*Note: Computing of ZMs for above mentioned galaxy and non-galaxy images are slightly consuming time. So, we upladed the zernike moments of both classes in this repository. To load the ZMs please use:*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqHJYkXEc5b4",
        "outputId": "d4bad796-a51a-4908-8a5c-e01e196a2f11"
      },
      "outputs": [],
      "source": [
        "galaxy_zm = pd.read_csv('/path/to/your/direcotry/galaxy_zms.csv')\n",
        "nongalaxy_zm = pd.read_csv('/path/to/your/direcotry/non_galaxy_zms.csv')\n",
        "\n",
        "galaxy_zm.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
        "nongalaxy_zm.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
        "\n",
        "zmg = np.array(galaxy_zm)\n",
        "zmng = np.array(nongalaxy_zm)\n",
        "\n",
        "all_zm_data = np.concatenate([zmg,zmng])\n",
        "len(zmg), len(zmng), len(all_zm_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use \"0\" for galaxy class labels and \"1\" for non-galaxy class labels.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhFySzRMYgzd",
        "outputId": "c15a32ef-902c-49f7-cad1-4edd548940f5"
      },
      "outputs": [],
      "source": [
        "galaxies_labels = np.zeros(len(zmg))\n",
        "nongalaxy_labels = np.ones(len(zmng))\n",
        "all_labels = np.concatenate([galaxies_labels, nongalaxy_labels])\n",
        "len(all_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### We split the data set into 75 percent traning set and 25 percent test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uV8388_eNlj"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(all_zm_data, all_labels, np.arange(len(all_labels)), \n",
        "                                                                                 test_size=0.25, shuffle=True, random_state=None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Since, the galaxy and non-galaxy classifiers are unbalance class models, so we used the class weight in the program:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_weights = {0: len(all_zm_data) / (2*len(zmg)), 1: len(all_zm_data) / (2*len(zmng))}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### The SVM model uses radial base kernel (rbf), C = 1.5, and gamma = 'scale' to fit the model on the training set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SVC(kernel='rbf', probability=True, C=1.5, gamma='scale',class_weight=class_weights)\n",
        "gz2_training_model = model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Now, we apply the test set to examine the classification algorithm. Using the predicted label by the machine on original labels, we compute the elements of the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "con = metrics.confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### To compare the performace of classifier with the random classifier, we calculate the reciver operation charecterstic curve (ROC curve). The area under the curve (AUC) shows the probability of True positive rates of the classifier. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
        "auc = metrics.roc_auc_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To measure the performance metrics of classifier, we compute (metrics names .....)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "GNkms73218l2",
        "outputId": "59c9e276-851b-4fc3-bc4e-8badb8c687a5"
      },
      "outputs": [],
      "source": [
        "performances \n",
        "\n",
        "acc = metrics.accuracy_score(y_test, y_pred)\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(all_zm_data, all_labels, np.arange(len(all_labels)), \n",
        "                                                                                 test_size=0.25, shuffle=True, random_state=None)\n",
        "\n",
        "y_train_encoded = to_categorical(y_train, num_classes=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_weights = {0: len(all_zm_data) / (2*len(zmg)), 1: len(all_zm_data) / (2*len(zmng))}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Due to one dimentional structure of ZMs, we used one dimentional achitecture of CNN: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# input value\n",
        "x = Input(shape=(all_zm_data.shape[1],1))\n",
        "\n",
        "#hidden layers\n",
        "c0 = Conv1D(256, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "b0 = BatchNormalization()(c0)\n",
        "m0 = MaxPooling1D(pool_size=2)(b0)\n",
        "d0 = Dropout(0.1)(m0)\n",
        "\n",
        "c1 = Conv1D(128, kernel_size=3, strides=2, padding=\"same\")(d0)\n",
        "b1 = BatchNormalization()(c1)\n",
        "m1 = MaxPooling1D(pool_size=2)(b1)\n",
        "d1 = Dropout(0.1)(m1)\n",
        "\n",
        "c2 = Conv1D(64, kernel_size=3, strides=2, padding=\"same\")(d1)\n",
        "b2 = BatchNormalization()(c2)\n",
        "m2 = MaxPooling1D(pool_size=2)(b2)\n",
        "d2 = Dropout(0.1)(m2)\n",
        "\n",
        "f = Flatten()(d2)\n",
        "\n",
        "# output\n",
        "de0 = Dense(64, activation='relu')(f)\n",
        "de1 = Dense(32, activation='relu')(de0)\n",
        "de2 = Dense(2, activation='softmax')(de1)\n",
        "\n",
        "model = Model(inputs=x, outputs=de2, name=\"cnn_zm_45_galaxy_nonegalaxy\")\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Callback Functions\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "b_size = 64\n",
        "e_num = 30\n",
        "\n",
        "history = model.fit(\n",
        "X_train, y_train_encoded,\n",
        "batch_size=b_size,\n",
        "epochs=e_num,\n",
        "class_weight=class_weights,\n",
        "verbose = 1,\n",
        "callbacks=es,\n",
        "validation_split=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "con0 = metrics.confusion_matrix(y_test, y_pred_labels)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_labels).ravel()\n",
        "\n",
        "acc = metrics.accuracy_score(y_test, y_pred_labels)\n",
        "\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_labels)\n",
        "\n",
        "auc = metrics.roc_auc_score(y_test, y_pred_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Three classifier models based on the original images:\n",
        "  \n",
        "- (Vision Transformers used as data augmentation tools on the Galaxy and Non-Galaxy images.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import packages \n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import (Dense, Dropout, Input,Conv2D, Flatten,\n",
        "                             MaxPooling2D,BatchNormalization)\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import ResNet50, VGG16\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "#Torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### To read the images of each class and convert to Pillow images we used the following function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_galaxy_images(data_dir, target_size):\n",
        "        \n",
        "        \"\"\"\n",
        "        Loads, resizes, and processes all JPG images from the specified directory.\n",
        "\n",
        "        Parameters:\n",
        "        data_dir (str): The directory containing the JPG images to be processed.\n",
        "        target_size (tuple): The target size for resizing the images, specified as (width, height).\n",
        "\n",
        "        Returns:\n",
        "        list: A list of PIL Image objects, each representing a resized and processed image.\n",
        "\n",
        "        The function performs the following steps:\n",
        "        1. Lists all JPG image files in the specified directory.\n",
        "        2. Reads each image using OpenCV.\n",
        "        3. Resizes each image to the specified target size.\n",
        "        4. Scales the pixel values and converts the image to a format compatible with PIL.\n",
        "        5. Converts each resized image to a PIL Image object.\n",
        "        6. Appends each PIL Image object to a list.\n",
        "        7. Returns the list of PIL Image objects.\n",
        "        \"\"\"\n",
        "\n",
        "        all_images = []\n",
        "\n",
        "        file_path = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir) if filename.endswith('.jpg')]\n",
        "\n",
        "        for img in file_path:\n",
        "            image = cv2.imread(img)\n",
        "            resized_images=cv2.resize(image, target_size)\n",
        "            resized_images = (resized_images * 255).astype(np.uint8)\n",
        "            pil_images = Image.fromarray(resized_images)\n",
        "            all_images.append(pil_images)\n",
        "\n",
        "        return all_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- To use our image data use these directories from the repo.:\n",
        "        \n",
        "        - galaxy: \n",
        "        - non-galaxy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_galaxy = '/path/to/your/direcotry/galaxy'\n",
        "path_non = '/path/to/your/direcotry/non_galaxy'\n",
        "\n",
        "image_size = 200\n",
        "\n",
        "g_img = load_galaxy_images(path_galaxy, target_size=(image_size,image_size))\n",
        "ng_img = load_galaxy_images(path_non, target_size=(image_size,image_size))\n",
        "\n",
        "all_data = g_img + ng_img\n",
        "np.shape(all_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### We define the vision transformer for both training and testing data sets: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# transforms for training data\n",
        "train_transform = transforms.Compose([transforms.CenterCrop(image_size),\n",
        "                                      transforms.RandomRotation(90),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.RandomVerticalFlip(),\n",
        "                                      transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0), ratio=(0.99, 1.01)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                                      ])\n",
        "\n",
        "\n",
        "# transforms for test data\n",
        "test_transform = transforms.Compose([transforms.CenterCrop(image_size),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                                      ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "galaxies_labels = np.zeros(len(g_img))\n",
        "nongalaxy_labels = np.ones(len(ng_img))\n",
        "\n",
        "all_labels = np.concatenate([galaxies_labels, nongalaxy_labels])\n",
        "len(all_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "b_size = 64\n",
        "e_num = 30\n",
        "\n",
        "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(all_data, all_labels, np.arange(len(all_labels)), test_size=0.25, shuffle=True, random_state=None)\n",
        "\n",
        "\n",
        "y_train_encoded = to_categorical(y_train, num_classes=2)\n",
        "class_weights = {0: len(all_data) / (2*len(g_img)), 1: len(all_data) / (2*len(ng_img))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# input\n",
        "    x = Input(shape=(image_size,image_size,3))\n",
        "\n",
        "    #hidden layers\n",
        "    c0 = Conv2D(256, kernel_size=(3,3), strides=(1,1), padding=\"same\")(x)\n",
        "    b0 = BatchNormalization()(c0)\n",
        "    m0 = MaxPooling2D(pool_size=(2, 2))(b0)\n",
        "    d0 = Dropout(0.1)(m0)\n",
        "\n",
        "    c1 = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding=\"same\")(m0)\n",
        "    b1 = BatchNormalization()(c1)\n",
        "    m1 = MaxPooling2D(pool_size=(2, 2))(b1)\n",
        "    d1 = Dropout(0.1)(m1)\n",
        "\n",
        "    c2 = Conv2D(64, kernel_size=(3,3), strides=(1,1), padding=\"same\")(m1)\n",
        "    b2 = BatchNormalization()(c2)\n",
        "    m2 = MaxPooling2D(pool_size=(2, 2))(b2)\n",
        "    d2 = Dropout(0.1)(m2)\n",
        "\n",
        "    f = Flatten()(m2)\n",
        "\n",
        "    # output layers\n",
        "    de0 = Dense(64, activation='relu')(f)\n",
        "    de1 = Dense(32, activation='relu')(de0)\n",
        "    de2 = Dense(2, activation='softmax')(de1)\n",
        "\n",
        "    model = Model(inputs=x, outputs=de2, name=\"cnn_transformer_galaxy_nonegalaxy\")\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "    \n",
        "\n",
        "# Callback Functions\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "history = model.fit(\n",
        "np.array(transformed_X_train), y_train_encoded,\n",
        "batch_size=b_size,\n",
        "epochs=e_num,\n",
        "verbose = 1,\n",
        "class_weight=class_weights,\n",
        "callbacks=es,\n",
        "validation_split=0.1\n",
        ")\n",
        "models.append(history)\n",
        "\n",
        "    y_pred = model.predict(np.array(transformed_X_test))\n",
        "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "    Y_pred.append(y_pred_labels)\n",
        "\n",
        "    con0 = metrics.confusion_matrix(y_test, y_pred_labels)\n",
        "    cons.append(con0)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_labels).ravel()\n",
        "    TN_list.append(tn)\n",
        "    FP_list.append(fp)\n",
        "    FN_list.append(fn)\n",
        "    TP_list.append(tp)\n",
        "\n",
        "    acc = metrics.accuracy_score(y_test, y_pred_labels)\n",
        "    accs.append(acc)\n",
        "\n",
        "    fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_labels)\n",
        "    fprs.append(fpr)\n",
        "    tprs.append(tpr)\n",
        "\n",
        "    auc = metrics.roc_auc_score(y_test, y_pred_labels)\n",
        "    aucs.append(auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### We apply the vision transformer for both training and testing samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformer for training data\n",
        "transformed_X_train=[]\n",
        "for i in range(len(X_train)):\n",
        "  transformed_train_images = train_transform(X_train[i])\n",
        "  new_image = np.transpose(transformed_train_images, (1, 2, 0))\n",
        "  transformed_X_train.append(new_image)\n",
        "\n",
        "# Transformer for testing data\n",
        "transformed_X_test=[]\n",
        "for j in range(len(X_test)):\n",
        "  transformed_test_images = test_transform(X_test[j])\n",
        "  new_images = np.transpose(transformed_test_images, (1, 2, 0))\n",
        "  transformed_X_test.append(new_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save any output you need.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "output_el_path = '/path/to/your/direcotry'\n",
        "import os\n",
        "pickle_el_filename = 'performances_of_galaxy_nonegalaxy.pickle'\n",
        "pickle_el_filepath = os.path.join(output_el_path, pickle_el_filename)\n",
        "\n",
        "with open(pickle_el_filepath, 'wb') as pickle_file:\n",
        "    pickle.dump(accs, pickle_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fit the ResNet50 model for 10 iterations and calculate the standard deviation.\n",
        "#### (You can save the performance materials and the models outputs.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "b_size = 64\n",
        "e_num = 30\n",
        "\n",
        "for i in range (10):\n",
        "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(all_data, all_labels, np.arange(len(all_labels)), test_size=0.25, shuffle=True, random_state=None)\n",
        "    y_test_list.append(y_test)\n",
        "    test_indx.append(test_indices)\n",
        "\n",
        "    y_train_encoded = to_categorical(y_train, num_classes=2)\n",
        "    class_weights = {0: len(all_data) / (2*len(g_img)), 1: len(all_data) / (2*len(ng_img))}\n",
        "\n",
        "    # Training data\n",
        "    transformed_X_train=[]\n",
        "    for i in range(len(X_train)):\n",
        "      transformed_train_images = train_transform(X_train[i])\n",
        "      new_image = np.transpose(transformed_train_images, (1, 2, 0))\n",
        "      transformed_X_train.append(new_image)\n",
        "\n",
        "    # Testing data\n",
        "    transformed_X_test=[]\n",
        "    for j in range(len(X_test)):\n",
        "      transformed_test_images = test_transform(X_test[j])\n",
        "      new_images = np.transpose(transformed_test_images, (1, 2, 0))\n",
        "      transformed_X_test.append(new_images)\n",
        "\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(64, activation='relu')(x)  # Add your custom layers here\n",
        "    output = Dense(2, activation='softmax')(x)  # 3 classes, so 3 output units with softmax activation\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "    history = model.fit(\n",
        "    np.array(transformed_X_train), y_train_encoded,\n",
        "    batch_size=b_size,\n",
        "    epochs=e_num,\n",
        "    verbose = 1,\n",
        "    callbacks=es,\n",
        "    class_weight=class_weights,\n",
        "    validation_split=0.1\n",
        "    )\n",
        "    models.append(history)\n",
        "\n",
        "    y_pred = model.predict(np.array(transformed_X_test))\n",
        "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "    Y_pred.append(y_pred_labels)\n",
        "\n",
        "    con0 = metrics.confusion_matrix(y_test, y_pred_labels)\n",
        "    cons.append(con0)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_labels).ravel()\n",
        "    TN_list.append(tn)\n",
        "    FP_list.append(fp)\n",
        "    FN_list.append(fn)\n",
        "    TP_list.append(tp)\n",
        "\n",
        "    acc = metrics.accuracy_score(y_test, y_pred_labels)\n",
        "    accs.append(acc)\n",
        "\n",
        "    fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_labels)\n",
        "    fprs.append(fpr)\n",
        "    tprs.append(tpr)\n",
        "\n",
        "    auc = metrics.roc_auc_score(y_test, y_pred_labels)\n",
        "    aucs.append(auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fit the VGG16 model for 10 iterations and calculate the standard deviation.\n",
        "#### (You can save the performance materials and the models outputs.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_list=[]\n",
        "models=[]\n",
        "Y_pred=[]\n",
        "accs=[]\n",
        "cons=[]\n",
        "aucs=[]\n",
        "fprs=[]\n",
        "tprs=[]\n",
        "TP_list = []\n",
        "FP_list = []\n",
        "TN_list = []\n",
        "FN_list = []\n",
        "test_indx=[]\n",
        "\n",
        "b_size = 64\n",
        "e_num = 30\n",
        "\n",
        "for i in range (10):\n",
        "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(all_data, all_labels, np.arange(len(all_labels)), test_size=0.25, shuffle=True, random_state=None)\n",
        "    y_test_list.append(y_test)\n",
        "    test_indx.append(test_indices)\n",
        "\n",
        "    y_train_encoded = to_categorical(y_train, num_classes=2)\n",
        "    class_weights = {0: len(all_data) / (2*len(g_img)), 1: len(all_data) / (2*len(ng_img))}\n",
        "\n",
        "    # Training data\n",
        "    transformed_X_train=[]\n",
        "    for i in range(len(X_train)):\n",
        "      transformed_train_images = train_transform(X_train[i])\n",
        "      new_image = np.transpose(transformed_train_images, (1, 2, 0))\n",
        "      transformed_X_train.append(new_image)\n",
        "\n",
        "    # Testing data\n",
        "    transformed_X_test=[]\n",
        "    for j in range(len(X_test)):\n",
        "      transformed_test_images = test_transform(X_test[j])\n",
        "      new_images = np.transpose(transformed_test_images, (1, 2, 0))\n",
        "      transformed_X_test.append(new_images)\n",
        "\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(64, activation='relu')(x)  # Add your custom layers here\n",
        "    output = Dense(2, activation='softmax')(x)  # 3 classes, so 3 output units with softmax activation\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "    history = model.fit(\n",
        "    np.array(transformed_X_train), y_train_encoded,\n",
        "    batch_size=b_size,\n",
        "    epochs=e_num,\n",
        "    verbose = 1,\n",
        "    callbacks=es,\n",
        "    class_weight=class_weights,\n",
        "    validation_split=0.1\n",
        "    )\n",
        "    models.append(history)\n",
        "\n",
        "    y_pred = model.predict(np.array(transformed_X_test))\n",
        "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "    Y_pred.append(y_pred_labels)\n",
        "\n",
        "    con0 = metrics.confusion_matrix(y_test, y_pred_labels)\n",
        "    cons.append(con0)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_labels).ravel()\n",
        "    TN_list.append(tn)\n",
        "    FP_list.append(fp)\n",
        "    FN_list.append(fn)\n",
        "    TP_list.append(tp)\n",
        "\n",
        "    acc = metrics.accuracy_score(y_test, y_pred_labels)\n",
        "    accs.append(acc)\n",
        "\n",
        "    fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_labels)\n",
        "    fprs.append(fpr)\n",
        "    tprs.append(tpr)\n",
        "\n",
        "    auc = metrics.roc_auc_score(y_test, y_pred_labels)\n",
        "    aucs.append(auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Performances:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def metric(tp, fp, fn, tn):\n",
        "    acu = (tp + tn) / (tp + tn + fn + fp)\n",
        "    pre_p = tp / (tp + fp)\n",
        "    pre_n = tn / (tn + fn)\n",
        "    recal_p = tp / (tp + fn)\n",
        "    recal_n = tn / (tn + fp)\n",
        "    f1_p = (2 * (pre_p) * (recal_p)) / ((pre_p) + (recal_p))\n",
        "    f1_n = (2 * (pre_n) * (recal_n)) / ((pre_n) + (recal_n))\n",
        "    tss = (tp / (tp + fn)) - (fp / (fp + tn))\n",
        "    return acu, pre_p, pre_n, recal_p, recal_n, tss, f1_p, f1_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "acus=[]\n",
        "pre_ps=[]\n",
        "pre_ns=[]\n",
        "recal_ps=[]\n",
        "recal_ns=[]\n",
        "tsss=[]\n",
        "f1_ps=[]\n",
        "f1_ns=[]\n",
        "\n",
        "# Calculate metrics for each set of TP, FP, FN, TN values\n",
        "performance_metrics = []\n",
        "for i in range(10):\n",
        "    acu, pre_p, pre_n, recal_p, recal_n, hss1, tss, f1_p, f1_n, hss2, gs = metric(TP_list[i], FP_list[i], FN_list[i], TN_list[i])\n",
        "    acus.append(acu)\n",
        "    pre_ps.append(pre_p)\n",
        "    pre_ns.append(pre_n)\n",
        "    recal_ps.append(recal_p)\n",
        "    recal_ns.append(recal_n)\n",
        "    tsss.append(tss)\n",
        "    f1_ps.append(f1_p)\n",
        "    f1_ns.append(f1_n)\n",
        "\n",
        "acus_mean = np.mean(acus)\n",
        "acus_std = np.std(acus)\n",
        "\n",
        "pre_ps_mean = np.mean(pre_ps)\n",
        "pre_ps_std = np.std(pre_ps)\n",
        "\n",
        "pre_ns_mean = np.mean(pre_ns)\n",
        "pre_ns_std = np.std(pre_ns)\n",
        "\n",
        "recal_ps_mean = np.mean(recal_ps)\n",
        "recal_ps_std = np.std(recal_ps)\n",
        "\n",
        "recal_ns_mean = np.mean(recal_ns)\n",
        "recal_ns_std = np.std(recal_ns)\n",
        "\n",
        "tsss_mean = np.mean(tsss)\n",
        "tsss_std = np.std(tsss)\n",
        "\n",
        "f1_ps_mean = np.mean(f1_ps)\n",
        "f1_ps_std = np.std(f1_ps)\n",
        "\n",
        "f1_ns_mean = np.mean(f1_ns)\n",
        "f1_ns_std = np.std(f1_ns)\n",
        "\n",
        "auc_mean = np.mean(aucs)\n",
        "auc_std = np.std(aucs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Mean and Standard Deviation Values:\")\n",
        "print(\"Accuracy - Mean:\", acus_mean, \"  Std:\", acus_std)\n",
        "print(\"Precision Positive - Mean:\", pre_ps_mean, \"  Std:\", pre_ps_std)\n",
        "print(\"Precision Negative - Mean:\", pre_ns_mean, \"  Std:\", pre_ns_std)\n",
        "print(\"F1 Positive - Mean:\", f1_ps_mean, \"  Std:\", f1_ps_std)\n",
        "print(\"F1 Negative - Mean:\", f1_ns_mean, \"  Std:\", f1_ns_std)\n",
        "print(\"Recall Positive - Mean:\", recal_ps_mean, \"  Std:\", recal_ps_std)\n",
        "print(\"Recall Negative - Mean:\", recal_ns_mean, \"  Std:\", recal_ns_std)\n",
        "print(\"TSS - Mean:\", tsss_mean, \"  Std:\", tsss_std)\n",
        "print(\"AUC - Mean:\", auc_mean, \"  Std:\", auc_std)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
