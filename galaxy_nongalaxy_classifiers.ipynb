{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Galaxy and Non-Galaxy Classifiers \n",
        "\n",
        "## 1. Base on Zernike moments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qma9b0d_c5b1"
      },
      "outputs": [],
      "source": [
        "#Import packages\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from tensorflow.keras.layers import (Dense, Dropout,BatchNormalization, Input, Conv1D, Flatten,\n",
        "                             MaxPooling1D)\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "#Scikit_learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (accuracy_score, classification_report,\n",
        "                             ConfusionMatrixDisplay, confusion_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT-FdU4Rz439",
        "outputId": "5ce40898-4f2c-4ff4-fb35-7146910c0e9f"
      },
      "outputs": [],
      "source": [
        "# If using Google Colab.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute the ZMs:\n",
        "\n",
        "##### The ZEMO python package [https://pypi.org/project/ZEMO/] [https://github.com/hmddev1/ZEMO] can be used to compute Zernike moments (Zms) for your images. This library is described in a research paper you can find online [[arxiv:2308.13562](https://arxiv.org/abs/2308.13562v2)]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ZEMO import zemo\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "image_size = 200\n",
        "zernike_order = 45\n",
        "\n",
        "ZBFSTR = zemo.zernike_bf(image_size, zernike_order, 1)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- To use our image data use these directories from the repo.:\n",
        "        \n",
        "        - galaxy: \n",
        "        - non-galaxy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = r'/path/to/your/directory/galaxy' \n",
        "\n",
        "image_files = [os.path.join(path, filename) for filename in os.listdir(path) if filename.endswith('.jpg')]\n",
        "len(image_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ZZ = []\n",
        "\n",
        "for img_path in image_files:\n",
        "    image = cv2.imread(img_path)\n",
        "    resized_image = cv2.resize(image, (image_size, image_size))\n",
        "    im = resized_image[:,:,0]\n",
        "    Z = np.abs(zemo.zernike_mom(np.array(im), ZBFSTR))\n",
        "    ZZ.append(Z)\n",
        "\n",
        "\n",
        "# Save the ZMs as data frame\n",
        "df = pd.DataFrame(ZZ)\n",
        "df.to_csv('/path/to/your/directory/galaxy_zms.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Read the Zernike moments data:\n",
        "\n",
        "- To use our Zernike moments data, use these directories from the repo.:\n",
        "\n",
        "        - galaxy: \n",
        "        - non-galaxy: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqHJYkXEc5b4",
        "outputId": "d4bad796-a51a-4908-8a5c-e01e196a2f11"
      },
      "outputs": [],
      "source": [
        "galaxy_zm = pd.read_csv('/path/to/your/direcotry/galaxy_zms.csv')\n",
        "nongalaxy_zm = pd.read_csv('/path/to/your/direcotry/non_galaxy_zms.csv')\n",
        "\n",
        "galaxy_zm.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
        "nongalaxy_zm.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
        "\n",
        "zmg = np.array(galaxy_zm)\n",
        "zmng = np.array(nongalaxy_zm)\n",
        "\n",
        "all_zm_data = np.concatenate([zmg,zmng])\n",
        "len(zmg), len(zmng), len(all_zm_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Defining the labels due to the length of zernike moment features \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhFySzRMYgzd",
        "outputId": "c15a32ef-902c-49f7-cad1-4edd548940f5"
      },
      "outputs": [],
      "source": [
        "galaxies_labels = np.zeros(len(zmg))\n",
        "nongalaxy_labels = np.ones(len(zmng))\n",
        "all_labels = np.concatenate([galaxies_labels, nongalaxy_labels])\n",
        "len(all_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fit the SVM model for 10 iterations and calculate the standard deviation.\n",
        "##### (You can save the performance materials and the models outputs.) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uV8388_eNlj"
      },
      "outputs": [],
      "source": [
        "y_test_list=[]\n",
        "models=[]\n",
        "Y_pred=[]\n",
        "accs=[]\n",
        "cons=[]\n",
        "test_indx = []\n",
        "\n",
        "for i in range (10):\n",
        "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(all_zm_data, all_labels, np.arange(len(all_labels)), test_size=0.25, shuffle=True, random_state=None)\n",
        "    y_test_list.append(y_test)\n",
        "    test_indx.append(test_indices)\n",
        "\n",
        "    class_weights = {0: len(all_zm_data) / (2*len(zmg)), 1: len(all_zm_data) / (2*len(zmng))}\n",
        "\n",
        "    model = SVC(kernel='rbf', probability=True, C=1.5, gamma='scale',class_weight=class_weights)\n",
        "    gz2_training_model = model.fit(X_train, y_train)\n",
        "    models.append(gz2_training_model)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    Y_pred.append(y_pred)\n",
        "\n",
        "    con0 = metrics.confusion_matrix(y_test, y_pred)\n",
        "    cons.append(con0)\n",
        "\n",
        "    acc = metrics.accuracy_score(y_test, y_pred)\n",
        "    accs.append(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "GNkms73218l2",
        "outputId": "59c9e276-851b-4fc3-bc4e-8badb8c687a5"
      },
      "outputs": [],
      "source": [
        "print(np.mean(accs), np.std(accs))\n",
        "plt.plot(accs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save any output you need.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exiMUnHBNOGJ"
      },
      "outputs": [],
      "source": [
        "output_el_path = '/path/to/your/direcotry'\n",
        "import os\n",
        "pickle_el_filename = 'performances_of_galaxy_nonegalaxy.pickle'\n",
        "pickle_el_filepath = os.path.join(output_el_path, pickle_el_filename)\n",
        "\n",
        "with open(pickle_el_filepath, 'wb') as pickle_file:\n",
        "    pickle.dump(accs, pickle_file)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fit the 1D-CNNmodel for 10 iterations and calculate the standard deviation.\n",
        "#### (You can save the performance materials and the models outputs.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "y_test_list=[]\n",
        "models=[]\n",
        "Y_pred=[]\n",
        "accs=[]\n",
        "cons=[]\n",
        "test_indx = []\n",
        "\n",
        "batch_size = 64\n",
        "NUM_EPOCH = 30\n",
        "\n",
        "for i in range (10):\n",
        "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(all_zm_data, all_labels, np.arange(len(all_labels)), test_size=0.25, shuffle=True, random_state=None)\n",
        "    y_test_list.append(y_test)\n",
        "    test_indx.append(test_indices)\n",
        "\n",
        "    class_weights = {0: len(all_zm_data) / (2*len(zmg1)), 1: len(all_zm_data) / (2*len(zms1))}\n",
        "    y_train_encoded = to_categorical(y_train, num_classes=2)\n",
        "\n",
        "    # input value due to the zernike order of 45 (1081 features)\n",
        "    x = Input(shape=(1081,1))\n",
        "\n",
        "    #hidden layers\n",
        "    c0 = Conv1D(256, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    b0 = BatchNormalization()(c0)\n",
        "    m0 = MaxPooling1D(pool_size=2)(b0)\n",
        "    d0 = Dropout(0.1)(m0)\n",
        "\n",
        "    c1 = Conv1D(128, kernel_size=3, strides=2, padding=\"same\")(d0)\n",
        "    b1 = BatchNormalization()(c1)\n",
        "    m1 = MaxPooling1D(pool_size=2)(b1)\n",
        "    d1 = Dropout(0.1)(m1)\n",
        "\n",
        "    c2 = Conv1D(64, kernel_size=3, strides=2, padding=\"same\")(d1)\n",
        "    b2 = BatchNormalization()(c2)\n",
        "    m2 = MaxPooling1D(pool_size=2)(b2)\n",
        "    d2 = Dropout(0.1)(m2)\n",
        "\n",
        "    f = Flatten()(d2)\n",
        "\n",
        "    # output\n",
        "    de0 = Dense(64, activation='relu')(f)\n",
        "    de1 = Dense(32, activation='relu')(de0)\n",
        "    de2 = Dense(2, activation='softmax')(de1)\n",
        "\n",
        "    model = Model(inputs=x, outputs=de2, name=\"cnn_zm_45_galaxy_nonegalaxy\")\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    # Callback Functions\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "    history = model.fit(\n",
        "    X_train, y_train_encoded,\n",
        "    batch_size=batch_size,\n",
        "    epochs=NUM_EPOCH,\n",
        "    class_weight=class_weights,\n",
        "    verbose = 1,\n",
        "    callbacks=es,\n",
        "    validation_split=0.1\n",
        "    )\n",
        "    models.append(history)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "    Y_pred.append(y_pred_labels)\n",
        "\n",
        "    con0 = metrics.confusion_matrix(y_test, y_pred_labels)\n",
        "    cons.append(con0)\n",
        "\n",
        "    acc = metrics.accuracy_score(y_test, y_pred_labels)\n",
        "    accs.append(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(np.mean(accs), np.std(accs))\n",
        "plt.plot(accs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save any output you need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_el_path = '/path/to/your/direcotry'\n",
        "import os\n",
        "pickle_el_filename = 'performances_of_galaxy_nonegalaxy.pickle'\n",
        "pickle_el_filepath = os.path.join(output_el_path, pickle_el_filename)\n",
        "\n",
        "with open(pickle_el_filepath, 'wb') as pickle_file:\n",
        "    pickle.dump(accs, pickle_file)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Base on original images \n",
        "- (Vision Transformers used as data augmentation tools on the Galaxy and Non-Galaxy images.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import packages \n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import (Dense, Dropout, Input,Conv2D, Flatten,\n",
        "                             MaxPooling2D,BatchNormalization)\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import ResNet50, VGG16\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "#Torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The load_galaxy_images functions uses for read and pre-process the input images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_galaxy_images(data_dir, target_size):\n",
        "        \n",
        "        \"\"\"\n",
        "        Loads, resizes, and processes all JPG images from the specified directory.\n",
        "\n",
        "        Parameters:\n",
        "        data_dir (str): The directory containing the JPG images to be processed.\n",
        "        target_size (tuple): The target size for resizing the images, specified as (width, height).\n",
        "\n",
        "        Returns:\n",
        "        list: A list of PIL Image objects, each representing a resized and processed image.\n",
        "\n",
        "        The function performs the following steps:\n",
        "        1. Lists all JPG image files in the specified directory.\n",
        "        2. Reads each image using OpenCV.\n",
        "        3. Resizes each image to the specified target size.\n",
        "        4. Scales the pixel values and converts the image to a format compatible with PIL.\n",
        "        5. Converts each resized image to a PIL Image object.\n",
        "        6. Appends each PIL Image object to a list.\n",
        "        7. Returns the list of PIL Image objects.\n",
        "        \"\"\"\n",
        "\n",
        "        all_images = []\n",
        "\n",
        "        file_path = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir) if filename.endswith('.jpg')]\n",
        "\n",
        "        for img in file_path:\n",
        "            image = cv2.imread(img)\n",
        "            resized_images=cv2.resize(image, target_size)\n",
        "            resized_images = (resized_images * 255).astype(np.uint8)\n",
        "            pil_images = Image.fromarray(resized_images)\n",
        "            all_images.append(pil_images)\n",
        "\n",
        "        return all_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- To use our image data use these directories from the repo.:\n",
        "        \n",
        "        - galaxy: \n",
        "        - non-galaxy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g_im = '/path/to/your/direcotry/galaxy'\n",
        "ng_im = '/path/to/your/direcotry/non_galaxy'\n",
        "\n",
        "categories = ['g', 'ng']\n",
        "\n",
        "image_size = 200\n",
        "\n",
        "g_img = load_galaxy_images(g_im, target_size=(image_size,image_size))\n",
        "ng_img = load_galaxy_images(ng_im, target_size=(image_size,image_size))\n",
        "\n",
        "all_data = g_img + ng_img\n",
        "np.shape(all_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### vision transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# transforms for training data\n",
        "train_transform = transforms.Compose([transforms.CenterCrop(image_size),\n",
        "                                      transforms.RandomRotation(90),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.RandomVerticalFlip(),\n",
        "                                      transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0), ratio=(0.99, 1.01)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                                      ])\n",
        "\n",
        "\n",
        "# transforms for test data\n",
        "test_transform = transforms.Compose([transforms.CenterCrop(image_size),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                                      ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "galaxies_labels = np.zeros(len(g_img))\n",
        "nongalaxy_labels = np.ones(len(ng_img))\n",
        "\n",
        "all_labels = np.concatenate([galaxies_labels, nongalaxy_labels])\n",
        "len(all_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fit the classis CNN layers for 10 iterations and calculate the standard deviation.\n",
        "#### (You can save the performance materials and the models outputs.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_list=[]\n",
        "models=[]\n",
        "Y_pred=[]\n",
        "accs=[]\n",
        "cons=[]\n",
        "test_indx=[]\n",
        "\n",
        "b_size = 64\n",
        "e_num = 30\n",
        "\n",
        "for i in range (10):\n",
        "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(all_data, all_labels, np.arange(len(all_labels)), test_size=0.25, shuffle=True, random_state=None)\n",
        "    y_test_list.append(y_test)\n",
        "    test_indx.append(test_indices)\n",
        "\n",
        "    y_train_encoded = to_categorical(y_train, num_classes=2)\n",
        "    class_weights = {0: len(all_data) / (2*len(g_img)), 1: len(all_data) / (2*len(ng_img))}\n",
        "\n",
        "    # Transformer for training data\n",
        "    transformed_X_train=[]\n",
        "    for i in range(len(X_train)):\n",
        "      transformed_train_images = train_transform(X_train[i])\n",
        "      new_image = np.transpose(transformed_train_images, (1, 2, 0))\n",
        "      transformed_X_train.append(new_image)\n",
        "\n",
        "    # Transformer for testing data\n",
        "    transformed_X_test=[]\n",
        "    for j in range(len(X_test)):\n",
        "      transformed_test_images = test_transform(X_test[j])\n",
        "      new_images = np.transpose(transformed_test_images, (1, 2, 0))\n",
        "      transformed_X_test.append(new_images)\n",
        "\n",
        "    # input\n",
        "    x = Input(shape=(image_size,image_size,3))\n",
        "\n",
        "    #hidden layers\n",
        "    c0 = Conv2D(256, kernel_size=(3,3), strides=(1,1), padding=\"same\")(x)\n",
        "    b0 = BatchNormalization()(c0)\n",
        "    m0 = MaxPooling2D(pool_size=(2, 2))(b0)\n",
        "    d0 = Dropout(0.1)(m0)\n",
        "\n",
        "    c1 = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding=\"same\")(m0)\n",
        "    b1 = BatchNormalization()(c1)\n",
        "    m1 = MaxPooling2D(pool_size=(2, 2))(b1)\n",
        "    d1 = Dropout(0.1)(m1)\n",
        "\n",
        "    c2 = Conv2D(64, kernel_size=(3,3), strides=(1,1), padding=\"same\")(m1)\n",
        "    b2 = BatchNormalization()(c2)\n",
        "    m2 = MaxPooling2D(pool_size=(2, 2))(b2)\n",
        "    d2 = Dropout(0.1)(m2)\n",
        "\n",
        "    f = Flatten()(m2)\n",
        "\n",
        "    # output layers\n",
        "    de0 = Dense(64, activation='relu')(f)\n",
        "    de1 = Dense(32, activation='relu')(de0)\n",
        "    de2 = Dense(2, activation='softmax')(de1)\n",
        "\n",
        "    model = Model(inputs=x, outputs=de2, name=\"cnn_transformer_galaxy_nonegalaxy\")\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    # Callback Functions\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "    history = model.fit(\n",
        "    np.array(transformed_X_train), y_train_encoded,\n",
        "    batch_size=b_size,\n",
        "    epochs=e_num,\n",
        "    verbose = 1,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=es,\n",
        "    validation_split=0.1\n",
        "    )\n",
        "    models.append(history)\n",
        "\n",
        "    y_pred = model.predict(np.array(transformed_X_test))\n",
        "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "    Y_pred.append(y_pred_labels)\n",
        "\n",
        "    con0 = metrics.confusion_matrix(y_test, y_pred_labels)\n",
        "    cons.append(con0)\n",
        "\n",
        "    acc = metrics.accuracy_score(y_test, y_pred_labels)\n",
        "    accs.append(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(np.mean(accs), np.std(accs))\n",
        "plt.plot(accs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save any output you need.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "output_el_path = '/path/to/your/direcotry'\n",
        "import os\n",
        "pickle_el_filename = 'performances_of_galaxy_nonegalaxy.pickle'\n",
        "pickle_el_filepath = os.path.join(output_el_path, pickle_el_filename)\n",
        "\n",
        "with open(pickle_el_filepath, 'wb') as pickle_file:\n",
        "    pickle.dump(accs, pickle_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fit the ResNet50 model for 10 iterations and calculate the standard deviation.\n",
        "#### (You can save the performance materials and the models outputs.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_list=[]\n",
        "models=[]\n",
        "Y_pred=[]\n",
        "accs=[]\n",
        "cons=[]\n",
        "test_indx=[]\n",
        "\n",
        "b_size = 64\n",
        "e_num = 30\n",
        "\n",
        "for i in range (10):\n",
        "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(all_data, all_labels, np.arange(len(all_labels)), test_size=0.25, shuffle=True, random_state=None)\n",
        "    y_test_list.append(y_test)\n",
        "    test_indx.append(test_indices)\n",
        "\n",
        "    y_train_encoded = to_categorical(y_train, num_classes=2)\n",
        "    class_weights = {0: len(all_data) / (2*len(g_img)), 1: len(all_data) / (2*len(ng_img))}\n",
        "\n",
        "    # Training data\n",
        "    transformed_X_train=[]\n",
        "    for i in range(len(X_train)):\n",
        "      transformed_train_images = train_transform(X_train[i])\n",
        "      new_image = np.transpose(transformed_train_images, (1, 2, 0))\n",
        "      transformed_X_train.append(new_image)\n",
        "\n",
        "    # Testing data\n",
        "    transformed_X_test=[]\n",
        "    for j in range(len(X_test)):\n",
        "      transformed_test_images = test_transform(X_test[j])\n",
        "      new_images = np.transpose(transformed_test_images, (1, 2, 0))\n",
        "      transformed_X_test.append(new_images)\n",
        "\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(64, activation='relu')(x)  # Add your custom layers here\n",
        "    output = Dense(2, activation='softmax')(x)  # 3 classes, so 3 output units with softmax activation\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "    history = model.fit(\n",
        "    np.array(transformed_X_train), y_train_encoded,\n",
        "    batch_size=b_size,\n",
        "    epochs=e_num,\n",
        "    verbose = 1,\n",
        "    callbacks=es,\n",
        "    class_weight=class_weights,\n",
        "    validation_split=0.1\n",
        "    )\n",
        "    models.append(history)\n",
        "\n",
        "    y_pred = model.predict(np.array(transformed_X_test))\n",
        "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "    Y_pred.append(y_pred_labels)\n",
        "\n",
        "    con0 = metrics.confusion_matrix(y_test, y_pred_labels)\n",
        "    cons.append(con0)\n",
        "\n",
        "    acc = metrics.accuracy_score(y_test, y_pred_labels)\n",
        "    accs.append(acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fit the VGG16 model for 10 iterations and calculate the standard deviation.\n",
        "#### (You can save the performance materials and the models outputs.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_list=[]\n",
        "models=[]\n",
        "Y_pred=[]\n",
        "accs=[]\n",
        "cons=[]\n",
        "test_indx=[]\n",
        "\n",
        "b_size = 64\n",
        "e_num = 30\n",
        "\n",
        "for i in range (10):\n",
        "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(all_data, all_labels, np.arange(len(all_labels)), test_size=0.25, shuffle=True, random_state=None)\n",
        "    y_test_list.append(y_test)\n",
        "    test_indx.append(test_indices)\n",
        "\n",
        "    y_train_encoded = to_categorical(y_train, num_classes=2)\n",
        "    class_weights = {0: len(all_data) / (2*len(g_img)), 1: len(all_data) / (2*len(ng_img))}\n",
        "\n",
        "    # Training data\n",
        "    transformed_X_train=[]\n",
        "    for i in range(len(X_train)):\n",
        "      transformed_train_images = train_transform(X_train[i])\n",
        "      new_image = np.transpose(transformed_train_images, (1, 2, 0))\n",
        "      transformed_X_train.append(new_image)\n",
        "\n",
        "    # Testing data\n",
        "    transformed_X_test=[]\n",
        "    for j in range(len(X_test)):\n",
        "      transformed_test_images = test_transform(X_test[j])\n",
        "      new_images = np.transpose(transformed_test_images, (1, 2, 0))\n",
        "      transformed_X_test.append(new_images)\n",
        "\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(64, activation='relu')(x)  # Add your custom layers here\n",
        "    output = Dense(2, activation='softmax')(x)  # 3 classes, so 3 output units with softmax activation\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "    history = model.fit(\n",
        "    np.array(transformed_X_train), y_train_encoded,\n",
        "    batch_size=b_size,\n",
        "    epochs=e_num,\n",
        "    verbose = 1,\n",
        "    callbacks=es,\n",
        "    class_weight=class_weights,\n",
        "    validation_split=0.1\n",
        "    )\n",
        "    models.append(history)\n",
        "\n",
        "    y_pred = model.predict(np.array(transformed_X_test))\n",
        "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "    Y_pred.append(y_pred_labels)\n",
        "\n",
        "    con0 = metrics.confusion_matrix(y_test, y_pred_labels)\n",
        "    cons.append(con0)\n",
        "\n",
        "    acc = metrics.accuracy_score(y_test, y_pred_labels)\n",
        "    accs.append(acc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
